{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "\n",
    "- 数据集切分按照疾病、种族进行\n",
    "\n",
    "- 目前只针对蛋白组\n",
    "\n",
    "- 分种族训练\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "2025-02-19 20:13:14,563\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-02-19 20:13:14,844\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-02-19 20:13:14,945\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from config import *\n",
    "import pandas as pd\n",
    "import json\n",
    "from ppp_prediction.utils import load_data\n",
    "from ppp_prediction.model import fit_best_model\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ppp_prediction.plot.utils import save_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Basic Variables\n",
    "\n",
    "groupByVar = \"Ethnic\"  # Ethnic\n",
    "omicsName = \"Prot_meanImpute\"  # used omics Name\n",
    "phenoDefineVersion = \"Lancet_Digital_Health_2019\"  # used pheno version\n",
    "\n",
    "## cutoff\n",
    "Case_cutoff = 50  # only over this number of cases will be used as a phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dirs\n",
    "covariates_dir = dataDir / \"covariates.feather\"\n",
    "omicsDataDir = dataDir / f\"Prot/{omicsName}.feather\"\n",
    "\n",
    "phenoDefineDir = dataDir / f\"{phenoDefineVersion}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 53021 samples and 2912 features with Prot_meanImpute\n",
      "Founded Pheno Files: 169\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eid</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>BSA</th>\n",
       "      <th>age</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>...</th>\n",
       "      <th>drug_ldl</th>\n",
       "      <th>drug_hdl</th>\n",
       "      <th>drug_tc</th>\n",
       "      <th>drug_sbp</th>\n",
       "      <th>drug_dbp</th>\n",
       "      <th>genotype_array</th>\n",
       "      <th>assessment_center</th>\n",
       "      <th>ancestry</th>\n",
       "      <th>ancestry_high_confi</th>\n",
       "      <th>Ethnic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000017</td>\n",
       "      <td>1.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>89.5</td>\n",
       "      <td>2.067876</td>\n",
       "      <td>56.0</td>\n",
       "      <td>-11.3690</td>\n",
       "      <td>3.56718</td>\n",
       "      <td>-1.975530</td>\n",
       "      <td>0.213937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>EUR</td>\n",
       "      <td>EUR</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>113.9</td>\n",
       "      <td>2.359755</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-12.1620</td>\n",
       "      <td>2.77470</td>\n",
       "      <td>0.175048</td>\n",
       "      <td>2.554930</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>EUR</td>\n",
       "      <td>EUR</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000038</td>\n",
       "      <td>1.0</td>\n",
       "      <td>179.5</td>\n",
       "      <td>112.2</td>\n",
       "      <td>2.365252</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-12.8698</td>\n",
       "      <td>6.41566</td>\n",
       "      <td>-5.106100</td>\n",
       "      <td>-1.296310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>EUR</td>\n",
       "      <td>EUR</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000042</td>\n",
       "      <td>1.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>77.1</td>\n",
       "      <td>1.902476</td>\n",
       "      <td>60.0</td>\n",
       "      <td>72.9437</td>\n",
       "      <td>-109.21600</td>\n",
       "      <td>74.692200</td>\n",
       "      <td>17.863400</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>SAS</td>\n",
       "      <td>SAS</td>\n",
       "      <td>Asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.805547</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-10.7174</td>\n",
       "      <td>5.77507</td>\n",
       "      <td>0.620341</td>\n",
       "      <td>0.505251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>EUR</td>\n",
       "      <td>EUR</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502404</th>\n",
       "      <td>6024086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.940218</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-11.1845</td>\n",
       "      <td>4.08367</td>\n",
       "      <td>-0.006942</td>\n",
       "      <td>-0.325017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>EUR</td>\n",
       "      <td>EUR</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502405</th>\n",
       "      <td>6024098</td>\n",
       "      <td>1.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>81.3</td>\n",
       "      <td>1.976592</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-13.3426</td>\n",
       "      <td>2.56658</td>\n",
       "      <td>-0.076882</td>\n",
       "      <td>6.048100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>EUR</td>\n",
       "      <td>EUR</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502406</th>\n",
       "      <td>6024103</td>\n",
       "      <td>1.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>111.3</td>\n",
       "      <td>2.404458</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-12.2113</td>\n",
       "      <td>4.22902</td>\n",
       "      <td>-2.629170</td>\n",
       "      <td>4.489250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>EUR</td>\n",
       "      <td>EUR</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502407</th>\n",
       "      <td>6024110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>73.2</td>\n",
       "      <td>1.897103</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-10.5527</td>\n",
       "      <td>6.84118</td>\n",
       "      <td>-2.149580</td>\n",
       "      <td>-0.825010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>EUR</td>\n",
       "      <td>EUR</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502408</th>\n",
       "      <td>6024122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>91.6</td>\n",
       "      <td>2.067527</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-11.4469</td>\n",
       "      <td>2.66226</td>\n",
       "      <td>-5.098050</td>\n",
       "      <td>0.441097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>EUR</td>\n",
       "      <td>EUR</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>502409 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            eid  sex  height  weight       BSA   age      PC1        PC2  \\\n",
       "0       1000017  1.0   172.0    89.5  2.067876  56.0 -11.3690    3.56718   \n",
       "1       1000025  1.0   176.0   113.9  2.359755  62.0 -12.1620    2.77470   \n",
       "2       1000038  1.0   179.5   112.2  2.365252  60.0 -12.8698    6.41566   \n",
       "3       1000042  1.0   169.0    77.1  1.902476  60.0  72.9437 -109.21600   \n",
       "4       1000056  0.0   163.0    72.0  1.805547  65.0 -10.7174    5.77507   \n",
       "...         ...  ...     ...     ...       ...   ...      ...        ...   \n",
       "502404  6024086  0.0   154.0    88.0  1.940218  66.0 -11.1845    4.08367   \n",
       "502405  6024098  1.0   173.0    81.3  1.976592  68.0 -13.3426    2.56658   \n",
       "502406  6024103  1.0   187.0   111.3  2.404458  61.0 -12.2113    4.22902   \n",
       "502407  6024110  1.0   177.0    73.2  1.897103  66.0 -10.5527    6.84118   \n",
       "502408  6024122  0.0   168.0    91.6  2.067527  66.0 -11.4469    2.66226   \n",
       "\n",
       "              PC3        PC4  ...  drug_ldl  drug_hdl  drug_tc  drug_sbp  \\\n",
       "0       -1.975530   0.213937  ...       0.0       0.0      0.0       1.0   \n",
       "1        0.175048   2.554930  ...       1.0       0.0      1.0       1.0   \n",
       "2       -5.106100  -1.296310  ...       0.0       0.0      0.0       1.0   \n",
       "3       74.692200  17.863400  ...       1.0       0.0      1.0       1.0   \n",
       "4        0.620341   0.505251  ...       0.0       0.0      0.0       0.0   \n",
       "...           ...        ...  ...       ...       ...      ...       ...   \n",
       "502404  -0.006942  -0.325017  ...       0.0       0.0      0.0       0.0   \n",
       "502405  -0.076882   6.048100  ...       0.0       1.0      0.0       1.0   \n",
       "502406  -2.629170   4.489250  ...       0.0       0.0      0.0       1.0   \n",
       "502407  -2.149580  -0.825010  ...       0.0       0.0      0.0       0.0   \n",
       "502408  -5.098050   0.441097  ...       0.0       0.0      0.0       0.0   \n",
       "\n",
       "        drug_dbp  genotype_array  assessment_center  ancestry  \\\n",
       "0            1.0               1                  1       EUR   \n",
       "1            1.0               2                  2       EUR   \n",
       "2            1.0               1                  3       EUR   \n",
       "3            1.0               2                  3       SAS   \n",
       "4            0.0               2                  4       EUR   \n",
       "...          ...             ...                ...       ...   \n",
       "502404       0.0               2                  8       EUR   \n",
       "502405       1.0               2                  9       EUR   \n",
       "502406       1.0               2                 20       EUR   \n",
       "502407       0.0               2                 11       EUR   \n",
       "502408       0.0               2                  2       EUR   \n",
       "\n",
       "        ancestry_high_confi  Ethnic  \n",
       "0                       EUR   White  \n",
       "1                       EUR   White  \n",
       "2                       EUR   White  \n",
       "3                       SAS   Asian  \n",
       "4                       EUR   White  \n",
       "...                     ...     ...  \n",
       "502404                  EUR   White  \n",
       "502405                  EUR   White  \n",
       "502406                  EUR   White  \n",
       "502407                  EUR   White  \n",
       "502408                  EUR   White  \n",
       "\n",
       "[502409 rows x 51 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "covariates_df = pd.read_feather(covariates_dir)\n",
    "omicsData = pd.read_feather(omicsDataDir)\n",
    "print(\n",
    "    f\"Total {omicsData.shape[0]} samples and {omicsData.shape[1]} features with {omicsName}\"\n",
    ")\n",
    "diseaseList = list(phenoDefineDir.glob(\"*.feather\"))\n",
    "foundedPhenoFile = len(list(phenoDefineDir.glob(\"*.feather\")))\n",
    "print(f\"Founded Pheno Files: {foundedPhenoFile}\")\n",
    "covariates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ethnic\n",
       "White      472610\n",
       "Asian        9879\n",
       "Black        8058\n",
       "Other        7335\n",
       "Mixed        2954\n",
       "Chinese      1573\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# groupByVar used\n",
    "used_groupByVar = [\"White\", \"Asian\", \"Black\"]\n",
    "covariates_df[groupByVar].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting...: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 169/169 [01:01<00:00,  2.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# show all disease rate in Prot\n",
    "\n",
    "\n",
    "res_dict = {\n",
    "    \"event\": [],\n",
    "    \"incident\": [],\n",
    "    \"prevalent\": [],\n",
    "}\n",
    "for disease in tqdm(diseaseList, total=len(diseaseList), desc=\"Counting...\"):\n",
    "    df = pd.read_feather(disease).query(\"eid in @omicsData.eid\")\n",
    "\n",
    "    for col in [\"event\", \"incident\", \"prevalent\"]:\n",
    "        case = int(df[col].sum())\n",
    "        control = int(df.shape[0] - case)\n",
    "        rate = case / df.shape[0]\n",
    "        res_dict[col].append(\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"Phenotype\": [disease.stem],\n",
    "                    \"Case\": [case],\n",
    "                    \"Control\": [control],\n",
    "                    \"Rate\": [rate],\n",
    "                }\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phenotype</th>\n",
       "      <th>Case</th>\n",
       "      <th>Control</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hypertension</td>\n",
       "      <td>18096</td>\n",
       "      <td>34925</td>\n",
       "      <td>0.341299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oth_organisms</td>\n",
       "      <td>9692</td>\n",
       "      <td>43329</td>\n",
       "      <td>0.182795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bacterial</td>\n",
       "      <td>9516</td>\n",
       "      <td>43505</td>\n",
       "      <td>0.179476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cataract</td>\n",
       "      <td>7811</td>\n",
       "      <td>45210</td>\n",
       "      <td>0.147319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>diverticuli</td>\n",
       "      <td>7732</td>\n",
       "      <td>45289</td>\n",
       "      <td>0.145829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>HBW</td>\n",
       "      <td>0</td>\n",
       "      <td>53021</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>neo_jaundice</td>\n",
       "      <td>0</td>\n",
       "      <td>53021</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>sepsis_newborn</td>\n",
       "      <td>0</td>\n",
       "      <td>53021</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>prematurity</td>\n",
       "      <td>0</td>\n",
       "      <td>53021</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>RDN</td>\n",
       "      <td>0</td>\n",
       "      <td>53021</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Phenotype   Case  Control      Rate\n",
       "0      hypertension  18096    34925  0.341299\n",
       "1     oth_organisms   9692    43329  0.182795\n",
       "2         bacterial   9516    43505  0.179476\n",
       "3          cataract   7811    45210  0.147319\n",
       "4       diverticuli   7732    45289  0.145829\n",
       "..              ...    ...      ...       ...\n",
       "164             HBW      0    53021  0.000000\n",
       "165    neo_jaundice      0    53021  0.000000\n",
       "166  sepsis_newborn      0    53021  0.000000\n",
       "167     prematurity      0    53021  0.000000\n",
       "168             RDN      0    53021  0.000000\n",
       "\n",
       "[169 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_df = (\n",
    "    pd.concat(res_dict[\"event\"])\n",
    "    .sort_values(\"Rate\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "incident_df = (\n",
    "    pd.concat(res_dict[\"incident\"])\n",
    "    .sort_values(\"Rate\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "prevalent_df = (\n",
    "    pd.concat(res_dict[\"prevalent\"])\n",
    "    .sort_values(\"Rate\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "event_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 0.2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# histplot\n",
    "sns.histplot(data=event_df, x=\"Rate\", ax=ax1, bins=50)\n",
    "sns.histplot(data=incident_df, x=\"Rate\", ax=ax2, bins=50)\n",
    "sns.histplot(data=prevalent_df, x=\"Rate\", ax=ax3, bins=50)\n",
    "\n",
    "ax1.set_title(\"Event\")\n",
    "ax2.set_title(\"Incident\")\n",
    "ax3.set_title(\"Prevalent\")\n",
    "\n",
    "ax1.set_xlim(0, 0.2)\n",
    "ax2.set_xlim(0, 0.2)\n",
    "ax3.set_xlim(0, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finnal Incident Phenotype: 141\n",
      "Finnal Prevalent Phenotype: 99\n"
     ]
    }
   ],
   "source": [
    "# event_df =\n",
    "incident_df = incident_df.query(\"Case > @Case_cutoff\")\n",
    "prevalent_df = prevalent_df.query(\"Case > @Case_cutoff\")\n",
    "\n",
    "print(f\"Finnal Incident Phenotype: {incident_df.shape[0]}\")\n",
    "print(f\"Finnal Prevalent Phenotype: {prevalent_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Run Assoc\n",
    "\n",
    "1. For prevalence, by Cox \n",
    "2. For incident, by logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Cox\n",
    "\n",
    "## step1 extract all sample size over 30 and run cox for Prot \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incident_df\n",
    "\n",
    "\n",
    "# cross_corr_v3.py -q /home/xutingfeng/ukb/project/renji/data/phewas/NMR.pkl -k compative_disease.feather --cond /home/xutingfeng/ukb/project/renji/data/cov.feather  --key_cols disease survTime --event_key_cols disease --date_key_cols survTime --comprisk_order control CAD AAA -t 4 --cond_cols age --cat_cond_cols sex assessment_center any_lipids_drug -o test.tsv\n",
    "\n",
    "# parallel -q echo \"cross_corr_v3.py  -q data/phewas/{2}.pkl -k output/02-PSM/PSM_matched_data_1_{3}_{5}_{4}_{1}.feather    --key_cols incident survTime --date_key_cols survTime --event_key_cols incident --cond output/covs.feather --cond_cols age BMI  --cat_cond_cols assessment_center sex any_lipids_drug any_lower_pressure_drug smoking   -o output/01-phewas/PSM_matched_data_1_{3}_{5}_{4}/{1}/{2}.tsv --norm_x zscore \" ::: CAD AAA  ::: NMR ::: 2 3 ::: glm ::: nearest |bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 过滤表型\n",
    "\n",
    "保存Case 至少>50的疾病\n",
    "\n",
    "分种族过滤！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppp_prediction.model_v2.models import (\n",
    "    fit_best_model_v2,\n",
    "    fit_ensemble_model_simple_v2,\n",
    "    fit_lightgbm,\n",
    "    fit_xgboost,\n",
    ")\n",
    "\n",
    "\n",
    "def get_predict_v2_from_df(\n",
    "    model,\n",
    "    data,\n",
    "    x_var,\n",
    "):\n",
    "    \"\"\"\n",
    "    merge by idx\n",
    "    \"\"\"\n",
    "\n",
    "    no_na_data = data[x_var].dropna().copy()\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        no_na_data[\"pred\"] = model.predict_proba(no_na_data)[:, 1]\n",
    "    else:\n",
    "        no_na_data[\"pred\"] = model.predict(no_na_data)\n",
    "\n",
    "    return (\n",
    "        data[[]]\n",
    "        .merge(no_na_data[[\"pred\"]], left_index=True, right_index=True, how=\"left\")\n",
    "        .values.flatten()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from ppp_prediction.metrics import cal_binary_metrics\n",
    "\n",
    "\n",
    "# define a function to fit the model, save the result and collect the scores\n",
    "## parallel this function\n",
    "def fit_model_and_save_result(\n",
    "    total_df,  # first col should be eid\n",
    "    label_df,  # first col should be eid\n",
    "    save_dir,\n",
    "    # asssoc_df=None, # used to sort and get top features to downsample, if None then will do assoc\n",
    "    feature_rank_list=None,  # used to downsample the features\n",
    "    min_class_number_cutoff={\"train\": 30, \"validation\": 10, \"test\": 10},\n",
    "    train_test_split_ratio=0.7,\n",
    "    seed=1234,\n",
    "    device=\"cuda\",\n",
    "    topk_list=[5, 10, 20, 50, 100],\n",
    "):\n",
    "    \"\"\"\n",
    "    1. merge the total_df and disease_df\n",
    "    2. check label_df sum is over min_class_number_cutoff; if not return None, and print the error\n",
    "    3. fit the models: 1) full lasso, 2) full xgboost, 3) sample lasso, 4) sample xgboost, 5) sample AutoTabPFN, 6) TabPFN\n",
    "    4. save the results: 1) model, 2) scores of total_df, 3) metrics of models\n",
    "    \"\"\"\n",
    "    # step1: merge and check\n",
    "\n",
    "    ## check the first column\n",
    "    if total_df.columns[0] != \"eid\":\n",
    "        raise ValueError(\"total_df first column should be eid\")\n",
    "    if label_df.columns[0] != \"eid\":\n",
    "        raise ValueError(\"label_df first column should be eid\")\n",
    "\n",
    "    features = total_df.columns[1:].tolist()\n",
    "    label = label_df.columns[1]\n",
    "\n",
    "    ## merge\n",
    "    merged_df = pd.merge(total_df, label_df, on=\"eid\", how=\"inner\")\n",
    "    print(\n",
    "        f\"Found merged samples: {merged_df.shape[0]} while, label_df: {label_df.shape[0]} and total_df: {total_df.shape[0]}\"\n",
    "    )\n",
    "\n",
    "    # step2: fit the model\n",
    "    ## step2.1 Train Test Split\n",
    "    train_df, test_df = train_test_split(\n",
    "        merged_df, test_size=1 - train_test_split_ratio, random_state=seed\n",
    "    )\n",
    "    train_df, val_df = train_test_split(train_df, test_size=0.3, random_state=seed)\n",
    "\n",
    "    score_df = pd.concat(\n",
    "        [\n",
    "            train_df[[\"eid\", label]].copy().assign(Type=\"train\"),\n",
    "            val_df[[\"eid\", label]].copy().assign(Type=\"validation\"),\n",
    "            test_df[[\"eid\", label]].copy().assign(Type=\"test\"),\n",
    "        ]\n",
    "    )\n",
    "    ## step2.2 check the min_class_number\n",
    "    for min_class_number_check_key in [\"train\", \"validation\", \"test\"]:\n",
    "        if min_class_number_check_key == \"train\":\n",
    "            to_check_df = train_df\n",
    "        elif min_class_number_check_key == \"validation\":\n",
    "            to_check_df = val_df\n",
    "        elif min_class_number_check_key == \"test\":\n",
    "            to_check_df = test_df\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"min_class_number_check_key should be in ['train', 'validation', 'test']\"\n",
    "            )\n",
    "        min_class_number = min(to_check_df[label].value_counts())\n",
    "        # the min class number and class name\n",
    "        min_class_name = to_check_df[label].value_counts().idxmin()\n",
    "        if min_class_number < min_class_number_cutoff[min_class_number_check_key]:\n",
    "            print(\n",
    "                f\"Error: {min_class_number_check_key} {min_class_name} has only {min_class_number} samples, less than {min_class_number_cutoff[min_class_number_check_key]}\"\n",
    "            )\n",
    "            return None\n",
    "    print(\n",
    "        f\"Train data have {train_df.shape[0]} samples with {train_df[label].sum():.0f} cases\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Validation data have {val_df.shape[0]} samples with {val_df[label].sum():.0f} cases\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Test data have {test_df.shape[0]} samples with {test_df[label].sum():.0f} cases\"\n",
    "    )\n",
    "\n",
    "    ## check\n",
    "    train_meta_info = {}\n",
    "    ## step2.4 fit the models\n",
    "    modelSaveDir = save_dir / \"models\"\n",
    "    modelSaveDir.mkdir(parents=True, exist_ok=True)\n",
    "    ### 1) Lasso full\n",
    "    lasso_full_savedir = modelSaveDir / \"lasso_full.pkl\"\n",
    "    if lasso_full_savedir.exists():\n",
    "        lasso_full = pickle.load(open(lasso_full_savedir, \"rb\"))\n",
    "        # print(f\"lasso_full loaded\")\n",
    "\n",
    "    else:\n",
    "        lasso_engine = \"cuml\" if device == \"cuda\" else \"sklearn\"\n",
    "        print(merged_df.shape)\n",
    "        if merged_df.shape[0] < 5000:\n",
    "            lasso_engine = \"sklearn\"\n",
    "        print(f\"lasso_full start with engine {lasso_engine}\")\n",
    "        (lasso_full, *_) = fit_best_model(\n",
    "            train_df=train_df,\n",
    "            test_df=val_df,\n",
    "            X_var=features,\n",
    "            y_var=label,\n",
    "            method_list=\"Lasso\",\n",
    "            cv=5,\n",
    "            engine=lasso_engine,\n",
    "        )\n",
    "\n",
    "        pickle.dump(lasso_full, open(lasso_full_savedir, \"wb\"))\n",
    "\n",
    "    score_df[\"lasso_full\"] = get_predict_v2_from_df(lasso_full, total_df, features)\n",
    "    # return lasso_full, score_df\n",
    "    train_meta_info[f\"lasso_full\"] = {\n",
    "        \"train_case\": train_df[label].sum(),\n",
    "        \"train_control\": train_df.shape[0] - train_df[label].sum(),\n",
    "    }\n",
    "    if isinstance(feature_rank_list, str):\n",
    "        if feature_rank_list == \"assoc\":\n",
    "            # feature_rank_list = lasso_full.coef_.argsort()\n",
    "            raise NotImplementedError(\"assoc not implemented\")\n",
    "            # pass\n",
    "        elif feature_rank_list == \"lasso\":\n",
    "            feature_rank_df = pd.DataFrame(\n",
    "                [lasso_full.feature_names_in_, lasso_full[-1].coef_]\n",
    "            ).T\n",
    "            feature_rank_df.columns = [\"feature\", \"coef\"]\n",
    "            feature_rank_df[\"abs_coef\"] = feature_rank_df[\"coef\"].abs()\n",
    "            feature_rank_df = feature_rank_df.sort_values(\"abs_coef\", ascending=False)\n",
    "\n",
    "            feature_rank_df.to_csv(\n",
    "                save_dir / \"feature_rank_lasso_full.csv\", index=False\n",
    "            )\n",
    "            feature_rank_list = feature_rank_df.query(\"abs_coef != 0 \")[\"feature\"].tolist()\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"feature_rank_list should be in ['assoc', 'lasso'] or a list of features with the first one is the most important\"\n",
    "            )\n",
    "    elif isinstance(feature_rank_list, list):\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"feature_rank_list should be in ['assoc', 'lasso'] or a list of features with the first one is the most important\"\n",
    "        )\n",
    "\n",
    "    del lasso_full\n",
    "\n",
    "    # xgboost full\n",
    "    xgboot_full_savedir = modelSaveDir / \"xgboost_full.pkl\"\n",
    "    if (modelSaveDir / \"xgboost_full.pkl\").exists():\n",
    "        print(f\"xgboost_full loaded\")\n",
    "        xgboost_full_tuned = pickle.load(open(xgboot_full_savedir, \"rb\"))\n",
    "    else:\n",
    "\n",
    "        xgboost_full_tuned, *_ = fit_xgboost(\n",
    "            train=train_df,\n",
    "            xvar=features,\n",
    "            label=label,\n",
    "            tuning=True,\n",
    "            tune_config={\"max_iter\": 100},\n",
    "        )\n",
    "        pickle.dump(xgboost_full_tuned, open(xgboot_full_savedir, \"wb\"))\n",
    "    score_df[\"xgboost_full\"] = get_predict_v2_from_df(\n",
    "        xgboost_full_tuned, total_df, features\n",
    "    )\n",
    "    train_meta_info[f\"xgboost_full\"] = {\n",
    "        \"train_case\": train_df[label].sum(),\n",
    "        \"train_control\": train_df.shape[0] - train_df[label].sum(),\n",
    "    }\n",
    "\n",
    "    del xgboost_full_tuned\n",
    "\n",
    "    for strata in [\"balance\", \n",
    "                   # \"random\"\n",
    "                  ]:  # balance or random\n",
    "        if strata == \"balance\":\n",
    "            disease_train_case = train_df.query(f\"{label} == 1\")\n",
    "            disease_train_case_number = min(disease_train_case.shape[0], 5000)\n",
    "\n",
    "            disease_train_case = disease_train_case.sample(\n",
    "                n = disease_train_case_number , random_state=seed, replace=False\n",
    "            )\n",
    "            \n",
    "            disease_train_control = train_df.query(f\"{label} == 0\").sample(\n",
    "                n=disease_train_case.shape[0], random_state=seed\n",
    "            )\n",
    "            disease_train_sample = pd.concat(\n",
    "                [disease_train_case, disease_train_control]\n",
    "            )\n",
    "        elif strata == \"random\":\n",
    "            if train_df.shape[0] > 10000:\n",
    "                disease_train_sample = train_df.sample(n=10000, random_state=seed)\n",
    "            else:\n",
    "                disease_train_sample = train_df  # TODO: Anno this with no sample\n",
    "\n",
    "        for topk in topk_list:\n",
    "            sig_features = feature_rank_list[:topk]\n",
    "\n",
    "            suffix_name = f\"{topk}_{strata}\"\n",
    "\n",
    "            print(suffix_name)\n",
    "\n",
    "            strata_topk_save_dir = modelSaveDir / f\"{topk}/{strata}\"\n",
    "            strata_topk_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            X_train = disease_train_sample[sig_features]\n",
    "            y_train = disease_train_sample[label]\n",
    "\n",
    "            lasso_sample_topk_savedir = strata_topk_save_dir / f\"lasso_sample.pkl\"\n",
    "            if lasso_sample_topk_savedir.exists():\n",
    "                lasso_sample = pickle.load(open(lasso_sample_topk_savedir, \"rb\"))\n",
    "                print(f\"lasso_sample_{suffix_name} loaded\")\n",
    "            else:\n",
    "                try:\n",
    "                    lasso_engine = \"cuml\" if device == \"cuda\" else \"sklearn\"\n",
    "                    if X_train.shape[0] < 5000:\n",
    "                        lasso_engine = \"sklearn\"\n",
    "                    print(f\"lasso_full start with engine {lasso_engine}\")\n",
    "\n",
    "                    (lasso_sample, *_) = fit_best_model(\n",
    "                        train_df=disease_train_sample,\n",
    "                        test_df=val_df,\n",
    "                        X_var=sig_features,\n",
    "                        y_var=label,\n",
    "                        method_list=\"Lasso\",\n",
    "                        cv=5,\n",
    "                        engine=lasso_engine,\n",
    "                    )\n",
    "                    pickle.dump(\n",
    "                        lasso_sample,\n",
    "                        open(strata_topk_save_dir / f\"lasso_sample.pkl\", \"wb\"),\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"lasso_sample_{topk} failed and erros: {e}\")\n",
    "\n",
    "            score_df[f\"lasso_sample_{suffix_name}\"] = get_predict_v2_from_df(\n",
    "                lasso_sample, total_df, sig_features\n",
    "            )\n",
    "            train_meta_info[f\"lasso_sample_{suffix_name}\"] = {\n",
    "                \"train_case\": disease_train_sample[label].sum(),\n",
    "                \"train_control\": disease_train_sample.shape[0]\n",
    "                - disease_train_sample[label].sum(),\n",
    "            }\n",
    "\n",
    "            del lasso_sample\n",
    "\n",
    "            from tabpfn_extensions.post_hoc_ensembles.sklearn_interface import (\n",
    "                AutoTabPFNClassifier,\n",
    "            )\n",
    "\n",
    "            AutoTabPFN_topk_savedir = strata_topk_save_dir / f\"AutoTabPFN.pkl\"\n",
    "            if AutoTabPFN_topk_savedir.exists():\n",
    "                AutoTabPFN = pickle.load(open(AutoTabPFN_topk_savedir, \"rb\"))\n",
    "                print(f\"AutoTabPFN_{topk} loaded\")\n",
    "            else:\n",
    "\n",
    "                try:\n",
    "                    AutoTabPFN = AutoTabPFNClassifier(\n",
    "                        max_time=120, device=\"cuda\" if device == \"cuda\" else \"cpu\", ignore_pretraining_limits=True\n",
    "                    )  # 120 seconds tuning time\n",
    "                    AutoTabPFN.fit(X_train, y_train)\n",
    "                    pickle.dump(\n",
    "                        AutoTabPFN, open(strata_topk_save_dir / f\"AutoTabPFN.pkl\", \"wb\")\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"AutoTabPFN_{topk} failed with {e}\")\n",
    "\n",
    "            # score_df[\"AutoTabPFN\"] = AutoTabPFN.predict_proba(X_held_out_test)[:, 1]\n",
    "            score_df[f\"AutoTabPFN_{suffix_name}\"] = AutoTabPFN.predict_proba(\n",
    "                total_df[sig_features]\n",
    "            )[:, 1]\n",
    "            train_meta_info[f\"AutoTabPFN_{suffix_name}\"] = {\n",
    "                \"train_case\": disease_train_sample[label].sum(),\n",
    "                \"train_control\": disease_train_sample.shape[0]\n",
    "                - disease_train_sample[label].sum(),\n",
    "            }\n",
    "\n",
    "            del AutoTabPFN\n",
    "            try:\n",
    "                from tabpfn import TabPFNClassifier\n",
    "\n",
    "                TabPFN_topk_savedir = strata_topk_save_dir / f\"TabPFN{topk}.pkl\"\n",
    "                if TabPFN_topk_savedir.exists():\n",
    "                    TabPFN = pickle.load(open(TabPFN_topk_savedir, \"rb\"))\n",
    "                    \n",
    "                    print(f\"TabPFN_{topk} loaded\")\n",
    "                else:\n",
    "\n",
    "                    TabPFN = TabPFNClassifier(\n",
    "                        device=\"cuda:0\" if device == \"cuda\" else \"cpu\",\n",
    "                        ignore_pretraining_limits=True,\n",
    "                    )\n",
    "                    TabPFN.fit(X_train, y_train)\n",
    "                    pickle.dump(\n",
    "                        TabPFN, open(strata_topk_save_dir / f\"TabPFN.pkl\", \"wb\")\n",
    "                    )\n",
    "                    # score_df[\"AutoTabPFN\"] = AutoTabPFN.predict_proba(X_held_out_test)[:, 1]\n",
    "                    score_df[f\"TabPFN_{suffix_name}\"] = TabPFN.predict_proba(\n",
    "                        total_df[sig_features]\n",
    "                    )[:, 1]\n",
    "                train_meta_info[f\"TabPFN_{suffix_name}\"] = {\n",
    "                    \"train_case\": disease_train_sample[label].sum(),\n",
    "                    \"train_control\": disease_train_sample.shape[0]\n",
    "                    - disease_train_sample[label].sum(),\n",
    "                }\n",
    "                del TabPFN\n",
    "            except Exception as e:\n",
    "                print(f\"TabPFN {topk} failed with {e}\")\n",
    "\n",
    "            # xgboost sampled\n",
    "            xgboost_sample_savedir = strata_topk_save_dir / f\"xgboost_sample.pkl\"\n",
    "            if xgboost_sample_savedir.exists():\n",
    "                xgboost_sample_tuned = pickle.load(open(xgboost_sample_savedir, \"rb\"))\n",
    "                print(f\"xgboost_sample_{topk} loaded\")\n",
    "            else:\n",
    "                try:\n",
    "                    xgboost_sample_tuned, *_ = fit_xgboost(\n",
    "                        train=disease_train_sample,\n",
    "                        xvar=sig_features,\n",
    "                        label=label,\n",
    "                        tuning=True,\n",
    "                        tune_config={\"max_iter\": 100},\n",
    "                    )\n",
    "                    pickle.dump(\n",
    "                        xgboost_sample_tuned,\n",
    "                        open(strata_topk_save_dir / f\"xgboost_sample.pkl\", \"wb\"),\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"xgboost_sample_{topk} failed\")\n",
    "\n",
    "            score_df[f\"xgboost_sample_{suffix_name}\"] = get_predict_v2_from_df(\n",
    "                xgboost_sample_tuned, total_df, sig_features\n",
    "            )\n",
    "            train_meta_info[f\"xgboost_sample_{suffix_name}\"] = {\n",
    "                \"train_case\": disease_train_sample[label].sum(),\n",
    "                \"train_control\": disease_train_sample.shape[0]\n",
    "                - disease_train_sample[label].sum(),\n",
    "            }\n",
    "\n",
    "            del xgboost_sample_tuned\n",
    "\n",
    "    score_df.to_feather(save_dir / \"held_out_test.feather\")\n",
    "    pickle.dump(train_meta_info, open(save_dir / \"train_meta_info.pkl\", \"wb\"))\n",
    "    metrics_list = []\n",
    "    for key in score_df.columns[3:]:  # eid label Type\n",
    "        to_cal_df = (\n",
    "            score_df.query(\"Type == 'test'\")[[\"eid\", label, key]].copy().dropna()\n",
    "        )\n",
    "        res = cal_binary_metrics(\n",
    "            to_cal_df[label], to_cal_df[key], n_resamples=30, ci=True\n",
    "        )\n",
    "        # res = run_cox(to_cal_df, var=key, E=E, T=T, ci=True, n_resamples=100)\n",
    "        res[\"method\"] = key\n",
    "        res.update(train_meta_info[key])\n",
    "        metrics_list.append(res)\n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "    metrics_df.to_csv(save_dir / \"metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultDir = outputDir / \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently, Running incident hypertension and White\n",
      "Found merged samples: 49442 while, label_df: 53021 and total_df: 49442\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:11\u001b[0m\n",
      "Cell \u001b[0;32mIn[18], line 47\u001b[0m, in \u001b[0;36mfit_model_and_save_result\u001b[0;34m(total_df, label_df, save_dir, feature_rank_list, min_class_number_cutoff, train_test_split_ratio, seed, device, topk_list)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# step2: fit the model\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m## step2.1 Train Test Split\u001b[39;00m\n\u001b[1;32m     44\u001b[0m train_df, test_df \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[1;32m     45\u001b[0m     merged_df, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m train_test_split_ratio, random_state\u001b[38;5;241m=\u001b[39mseed\n\u001b[1;32m     46\u001b[0m )\n\u001b[0;32m---> 47\u001b[0m train_df, val_df \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m score_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(\n\u001b[1;32m     50\u001b[0m     [\n\u001b[1;32m     51\u001b[0m         train_df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meid\u001b[39m\u001b[38;5;124m\"\u001b[39m, label]]\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39massign(Type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m     ]\n\u001b[1;32m     55\u001b[0m )\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m## step2.2 check the min_class_number\u001b[39;00m\n",
      "File \u001b[0;32m/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/sklearn/model_selection/_split.py:2876\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2872\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[1;32m   2874\u001b[0m train, test \u001b[38;5;241m=\u001b[39m ensure_common_namespace_device(arrays[\u001b[38;5;241m0\u001b[39m], train, test)\n\u001b[0;32m-> 2876\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_iterable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2878\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\n\u001b[1;32m   2879\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/sklearn/model_selection/_split.py:2878\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2872\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[1;32m   2874\u001b[0m train, test \u001b[38;5;241m=\u001b[39m ensure_common_namespace_device(arrays[\u001b[38;5;241m0\u001b[39m], train, test)\n\u001b[1;32m   2876\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   2877\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m-> 2878\u001b[0m         (\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m, _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[1;32m   2879\u001b[0m     )\n\u001b[1;32m   2880\u001b[0m )\n",
      "File \u001b[0;32m/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/sklearn/utils/_indexing.py:266\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[0;34m(X, indices, axis)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecifying the columns using strings is only supported for dataframes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m     )\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;66;03m# TODO: we should probably use _is_pandas_df_or_series(X) instead but this\u001b[39;00m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;66;03m# would require updating some tests such as test_train_test_split_mock_pandas.\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pandas_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_polars_df_or_series(X):\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _polars_indexing(X, indices, indices_dtype, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/sklearn/utils/_indexing.py:47\u001b[0m, in \u001b[0;36m_pandas_indexing\u001b[0;34m(X, key, key_dtype, axis)\u001b[0m\n\u001b[1;32m     42\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key_dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(key)):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# using take() instead of iloc[] ensures the return value is a \"proper\"\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# copy that will not raise SettingWithCopyWarning\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# check whether we should index with loc or iloc\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc \u001b[38;5;28;01mif\u001b[39;00m key_dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mloc\n",
      "File \u001b[0;32m/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/pandas/core/generic.py:4133\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   4128\u001b[0m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[1;32m   4129\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[1;32m   4130\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[1;32m   4131\u001b[0m     )\n\u001b[0;32m-> 4133\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4135\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   4139\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4140\u001b[0m )\n",
      "File \u001b[0;32m/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/pandas/core/internals/managers.py:894\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    891\u001b[0m indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[1;32m    893\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m--> 894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/pandas/core/internals/managers.py:687\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[1;32m    681\u001b[0m         indexer,\n\u001b[1;32m    682\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m    683\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[1;32m    684\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    698\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m    699\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[0;32m/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/pandas/core/internals/managers.py:688\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[1;32m    681\u001b[0m         indexer,\n\u001b[1;32m    682\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m    683\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[1;32m    684\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 688\u001b[0m         \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[1;32m    696\u001b[0m     ]\n\u001b[1;32m    698\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m    699\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[0;32m/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/pandas/core/internals/blocks.py:1307\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[1;32m   1304\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[0;32m-> 1307\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[1;32m   1314\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[1;32m   1315\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[0;32m/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/pandas/core/array_algos/take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[1;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/pandas/core/array_algos/take.py:162\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    157\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    159\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[1;32m    160\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[1;32m    161\u001b[0m )\n\u001b[0;32m--> 162\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flip_order:\n\u001b[1;32m    165\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# for disease in diseaseList:\n",
    "for disease in [Path(\"V1/data/Lancet_Digital_Health_2019/hypertension.feather\")]:\n",
    "    diseaseName = disease.stem\n",
    "    # for c_groupbyVar in used_groupByVar:\n",
    "    for c_groupbyVar in [\"White\"]:\n",
    "        # for label in [\"prevalent\", \"incident\"]:\n",
    "        c_groupbyVar_eids = covariates_df.query(f\"{groupByVar} == @c_groupbyVar\").eid\n",
    "        for label in [\"incident\", \"prevalent\"]:\n",
    "            print(f\"Currently, Running {label} {diseaseName} and {c_groupbyVar}\")\n",
    "            label_df = pd.read_feather(disease).query(\"eid in @omicsData.eid\")\n",
    "            res = fit_model_and_save_result(\n",
    "                total_df=omicsData.query(f\"eid in @c_groupbyVar_eids\"),\n",
    "                label_df=label_df[[\"eid\", label]],\n",
    "                save_dir=resultDir / f\"{diseaseName}/{c_groupbyVar}/{label}\",\n",
    "                feature_rank_list=\"lasso\",  # currently use the fake rank list, better use assoc on whole set or run assoc on the train set\n",
    "                device=\"cuda\",\n",
    "                topk_list=[5, 10],\n",
    "            )\n",
    "            break\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score_df = pd.read_feather(\"V1/output/test/hypertension/White/incident/held_out_test.feather\")\n",
    "metrics_list = []\n",
    "for key in score_df.columns[3:]:\n",
    "    to_cal_df = score_df.query(\"Type == 'test'\")[[\"eid\", label, key]].copy().dropna()\n",
    "    res = cal_binary_metrics(\n",
    "        to_cal_df[label], to_cal_df[key], n_resamples=30, ci=True\n",
    "    )\n",
    "    # res = run_cox(to_cal_df, var=key, E=E, T=T, ci=True, n_resamples=100)\n",
    "    res[\"method\"] = key\n",
    "    metrics_list.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eid</th>\n",
       "      <th>incident</th>\n",
       "      <th>Type</th>\n",
       "      <th>lasso_full</th>\n",
       "      <th>xgboost_full</th>\n",
       "      <th>lasso_sample_5_balance</th>\n",
       "      <th>AutoTabPFN_5_balance</th>\n",
       "      <th>TabPFN_5_balance</th>\n",
       "      <th>xgboost_sample_5_balance</th>\n",
       "      <th>lasso_sample_10_balance</th>\n",
       "      <th>AutoTabPFN_10_balance</th>\n",
       "      <th>TabPFN_10_balance</th>\n",
       "      <th>xgboost_sample_10_balance</th>\n",
       "      <th>lasso_sample_20_balance</th>\n",
       "      <th>AutoTabPFN_20_balance</th>\n",
       "      <th>TabPFN_20_balance</th>\n",
       "      <th>xgboost_sample_20_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36467</th>\n",
       "      <td>4717858</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.022516</td>\n",
       "      <td>0.160115</td>\n",
       "      <td>0.255544</td>\n",
       "      <td>0.185411</td>\n",
       "      <td>0.195054</td>\n",
       "      <td>0.357783</td>\n",
       "      <td>0.177245</td>\n",
       "      <td>0.100927</td>\n",
       "      <td>0.114464</td>\n",
       "      <td>0.494885</td>\n",
       "      <td>0.184815</td>\n",
       "      <td>0.154265</td>\n",
       "      <td>0.133417</td>\n",
       "      <td>0.498293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40639</th>\n",
       "      <td>5140388</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.217908</td>\n",
       "      <td>0.188215</td>\n",
       "      <td>0.402142</td>\n",
       "      <td>0.381195</td>\n",
       "      <td>0.386042</td>\n",
       "      <td>0.378526</td>\n",
       "      <td>0.289071</td>\n",
       "      <td>0.263934</td>\n",
       "      <td>0.267943</td>\n",
       "      <td>0.495328</td>\n",
       "      <td>0.322815</td>\n",
       "      <td>0.323159</td>\n",
       "      <td>0.301022</td>\n",
       "      <td>0.499192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35369</th>\n",
       "      <td>4607813</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.118593</td>\n",
       "      <td>0.162985</td>\n",
       "      <td>0.379269</td>\n",
       "      <td>0.333229</td>\n",
       "      <td>0.330958</td>\n",
       "      <td>0.393262</td>\n",
       "      <td>0.272855</td>\n",
       "      <td>0.209982</td>\n",
       "      <td>0.196092</td>\n",
       "      <td>0.494091</td>\n",
       "      <td>0.251587</td>\n",
       "      <td>0.156563</td>\n",
       "      <td>0.158057</td>\n",
       "      <td>0.498014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21917</th>\n",
       "      <td>3215162</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>-0.004587</td>\n",
       "      <td>0.188474</td>\n",
       "      <td>0.336355</td>\n",
       "      <td>0.281780</td>\n",
       "      <td>0.283694</td>\n",
       "      <td>0.377587</td>\n",
       "      <td>0.260952</td>\n",
       "      <td>0.179053</td>\n",
       "      <td>0.179263</td>\n",
       "      <td>0.493425</td>\n",
       "      <td>0.185442</td>\n",
       "      <td>0.152709</td>\n",
       "      <td>0.144786</td>\n",
       "      <td>0.498030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14736</th>\n",
       "      <td>2483295</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.337454</td>\n",
       "      <td>0.292529</td>\n",
       "      <td>0.407918</td>\n",
       "      <td>0.408023</td>\n",
       "      <td>0.401048</td>\n",
       "      <td>0.458739</td>\n",
       "      <td>0.417146</td>\n",
       "      <td>0.341036</td>\n",
       "      <td>0.343110</td>\n",
       "      <td>0.499990</td>\n",
       "      <td>0.545243</td>\n",
       "      <td>0.509983</td>\n",
       "      <td>0.510270</td>\n",
       "      <td>0.500417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26692</th>\n",
       "      <td>3723705</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>0.467860</td>\n",
       "      <td>0.341653</td>\n",
       "      <td>0.656962</td>\n",
       "      <td>0.685844</td>\n",
       "      <td>0.689476</td>\n",
       "      <td>0.572780</td>\n",
       "      <td>0.706430</td>\n",
       "      <td>0.749034</td>\n",
       "      <td>0.762235</td>\n",
       "      <td>0.501271</td>\n",
       "      <td>0.664229</td>\n",
       "      <td>0.720228</td>\n",
       "      <td>0.714066</td>\n",
       "      <td>0.501846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44574</th>\n",
       "      <td>5528979</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>0.263110</td>\n",
       "      <td>0.374805</td>\n",
       "      <td>0.421220</td>\n",
       "      <td>0.435431</td>\n",
       "      <td>0.438286</td>\n",
       "      <td>0.533529</td>\n",
       "      <td>0.510978</td>\n",
       "      <td>0.711149</td>\n",
       "      <td>0.711054</td>\n",
       "      <td>0.502870</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>0.657809</td>\n",
       "      <td>0.653734</td>\n",
       "      <td>0.502494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48845</th>\n",
       "      <td>5967237</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.034537</td>\n",
       "      <td>0.157668</td>\n",
       "      <td>0.200637</td>\n",
       "      <td>0.144268</td>\n",
       "      <td>0.146035</td>\n",
       "      <td>0.307546</td>\n",
       "      <td>0.174320</td>\n",
       "      <td>0.113595</td>\n",
       "      <td>0.115423</td>\n",
       "      <td>0.493637</td>\n",
       "      <td>0.203988</td>\n",
       "      <td>0.128150</td>\n",
       "      <td>0.132470</td>\n",
       "      <td>0.498159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24144</th>\n",
       "      <td>3455574</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>0.405940</td>\n",
       "      <td>0.352367</td>\n",
       "      <td>0.726913</td>\n",
       "      <td>0.688602</td>\n",
       "      <td>0.688561</td>\n",
       "      <td>0.574733</td>\n",
       "      <td>0.746596</td>\n",
       "      <td>0.639348</td>\n",
       "      <td>0.641678</td>\n",
       "      <td>0.502956</td>\n",
       "      <td>0.700807</td>\n",
       "      <td>0.651314</td>\n",
       "      <td>0.648113</td>\n",
       "      <td>0.500958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33610</th>\n",
       "      <td>4427050</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>0.266754</td>\n",
       "      <td>0.270343</td>\n",
       "      <td>0.419895</td>\n",
       "      <td>0.462636</td>\n",
       "      <td>0.466365</td>\n",
       "      <td>0.561863</td>\n",
       "      <td>0.493341</td>\n",
       "      <td>0.504434</td>\n",
       "      <td>0.482338</td>\n",
       "      <td>0.500124</td>\n",
       "      <td>0.406608</td>\n",
       "      <td>0.400406</td>\n",
       "      <td>0.394352</td>\n",
       "      <td>0.499760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49442 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           eid  incident   Type  lasso_full  xgboost_full  \\\n",
       "36467  4717858         1  train    0.022516      0.160115   \n",
       "40639  5140388         0  train    0.217908      0.188215   \n",
       "35369  4607813         1  train    0.118593      0.162985   \n",
       "21917  3215162         1  train   -0.004587      0.188474   \n",
       "14736  2483295         1  train    0.337454      0.292529   \n",
       "...        ...       ...    ...         ...           ...   \n",
       "26692  3723705         1   test    0.467860      0.341653   \n",
       "44574  5528979         0   test    0.263110      0.374805   \n",
       "48845  5967237         0   test   -0.034537      0.157668   \n",
       "24144  3455574         0   test    0.405940      0.352367   \n",
       "33610  4427050         0   test    0.266754      0.270343   \n",
       "\n",
       "       lasso_sample_5_balance  AutoTabPFN_5_balance  TabPFN_5_balance  \\\n",
       "36467                0.255544              0.185411          0.195054   \n",
       "40639                0.402142              0.381195          0.386042   \n",
       "35369                0.379269              0.333229          0.330958   \n",
       "21917                0.336355              0.281780          0.283694   \n",
       "14736                0.407918              0.408023          0.401048   \n",
       "...                       ...                   ...               ...   \n",
       "26692                0.656962              0.685844          0.689476   \n",
       "44574                0.421220              0.435431          0.438286   \n",
       "48845                0.200637              0.144268          0.146035   \n",
       "24144                0.726913              0.688602          0.688561   \n",
       "33610                0.419895              0.462636          0.466365   \n",
       "\n",
       "       xgboost_sample_5_balance  lasso_sample_10_balance  \\\n",
       "36467                  0.357783                 0.177245   \n",
       "40639                  0.378526                 0.289071   \n",
       "35369                  0.393262                 0.272855   \n",
       "21917                  0.377587                 0.260952   \n",
       "14736                  0.458739                 0.417146   \n",
       "...                         ...                      ...   \n",
       "26692                  0.572780                 0.706430   \n",
       "44574                  0.533529                 0.510978   \n",
       "48845                  0.307546                 0.174320   \n",
       "24144                  0.574733                 0.746596   \n",
       "33610                  0.561863                 0.493341   \n",
       "\n",
       "       AutoTabPFN_10_balance  TabPFN_10_balance  xgboost_sample_10_balance  \\\n",
       "36467               0.100927           0.114464                   0.494885   \n",
       "40639               0.263934           0.267943                   0.495328   \n",
       "35369               0.209982           0.196092                   0.494091   \n",
       "21917               0.179053           0.179263                   0.493425   \n",
       "14736               0.341036           0.343110                   0.499990   \n",
       "...                      ...                ...                        ...   \n",
       "26692               0.749034           0.762235                   0.501271   \n",
       "44574               0.711149           0.711054                   0.502870   \n",
       "48845               0.113595           0.115423                   0.493637   \n",
       "24144               0.639348           0.641678                   0.502956   \n",
       "33610               0.504434           0.482338                   0.500124   \n",
       "\n",
       "       lasso_sample_20_balance  AutoTabPFN_20_balance  TabPFN_20_balance  \\\n",
       "36467                 0.184815               0.154265           0.133417   \n",
       "40639                 0.322815               0.323159           0.301022   \n",
       "35369                 0.251587               0.156563           0.158057   \n",
       "21917                 0.185442               0.152709           0.144786   \n",
       "14736                 0.545243               0.509983           0.510270   \n",
       "...                        ...                    ...                ...   \n",
       "26692                 0.664229               0.720228           0.714066   \n",
       "44574                 0.433884               0.657809           0.653734   \n",
       "48845                 0.203988               0.128150           0.132470   \n",
       "24144                 0.700807               0.651314           0.648113   \n",
       "33610                 0.406608               0.400406           0.394352   \n",
       "\n",
       "       xgboost_sample_20_balance  \n",
       "36467                   0.498293  \n",
       "40639                   0.499192  \n",
       "35369                   0.498014  \n",
       "21917                   0.498030  \n",
       "14736                   0.500417  \n",
       "...                          ...  \n",
       "26692                   0.501846  \n",
       "44574                   0.502494  \n",
       "48845                   0.498159  \n",
       "24144                   0.500958  \n",
       "33610                   0.499760  \n",
       "\n",
       "[49442 rows x 17 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>AUC_UCI</th>\n",
       "      <th>AUC_LCI</th>\n",
       "      <th>ACC</th>\n",
       "      <th>ACC_UCI</th>\n",
       "      <th>ACC_LCI</th>\n",
       "      <th>Macro_F1</th>\n",
       "      <th>Macro_F1_UCI</th>\n",
       "      <th>Macro_F1_LCI</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>...</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Specificity_UCI</th>\n",
       "      <th>Specificity_LCI</th>\n",
       "      <th>APR</th>\n",
       "      <th>APR_UCI</th>\n",
       "      <th>APR_LCI</th>\n",
       "      <th>N</th>\n",
       "      <th>N_case</th>\n",
       "      <th>N_control</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.490933</td>\n",
       "      <td>0.499805</td>\n",
       "      <td>0.478778</td>\n",
       "      <td>0.705521</td>\n",
       "      <td>0.711436</td>\n",
       "      <td>0.697701</td>\n",
       "      <td>0.487309</td>\n",
       "      <td>0.493444</td>\n",
       "      <td>0.480732</td>\n",
       "      <td>0.106285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905177</td>\n",
       "      <td>0.908005</td>\n",
       "      <td>0.900284</td>\n",
       "      <td>0.248384</td>\n",
       "      <td>0.261198</td>\n",
       "      <td>0.239987</td>\n",
       "      <td>14833</td>\n",
       "      <td>3707</td>\n",
       "      <td>11126</td>\n",
       "      <td>lasso_full</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.491894</td>\n",
       "      <td>0.500239</td>\n",
       "      <td>0.480308</td>\n",
       "      <td>0.689881</td>\n",
       "      <td>0.695193</td>\n",
       "      <td>0.683933</td>\n",
       "      <td>0.488936</td>\n",
       "      <td>0.496889</td>\n",
       "      <td>0.483489</td>\n",
       "      <td>0.125708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.877854</td>\n",
       "      <td>0.884906</td>\n",
       "      <td>0.874051</td>\n",
       "      <td>0.246601</td>\n",
       "      <td>0.255733</td>\n",
       "      <td>0.236508</td>\n",
       "      <td>14833</td>\n",
       "      <td>3707</td>\n",
       "      <td>11126</td>\n",
       "      <td>xgboost_full</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.495396</td>\n",
       "      <td>0.503295</td>\n",
       "      <td>0.486836</td>\n",
       "      <td>0.589227</td>\n",
       "      <td>0.594605</td>\n",
       "      <td>0.582876</td>\n",
       "      <td>0.500898</td>\n",
       "      <td>0.508388</td>\n",
       "      <td>0.496095</td>\n",
       "      <td>0.337200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.673198</td>\n",
       "      <td>0.681983</td>\n",
       "      <td>0.666645</td>\n",
       "      <td>0.248695</td>\n",
       "      <td>0.259715</td>\n",
       "      <td>0.241147</td>\n",
       "      <td>14833</td>\n",
       "      <td>3707</td>\n",
       "      <td>11126</td>\n",
       "      <td>lasso_sample_5_balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.496205</td>\n",
       "      <td>0.506790</td>\n",
       "      <td>0.486198</td>\n",
       "      <td>0.607699</td>\n",
       "      <td>0.615133</td>\n",
       "      <td>0.605565</td>\n",
       "      <td>0.504705</td>\n",
       "      <td>0.516875</td>\n",
       "      <td>0.494315</td>\n",
       "      <td>0.303480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.709060</td>\n",
       "      <td>0.713843</td>\n",
       "      <td>0.702477</td>\n",
       "      <td>0.248550</td>\n",
       "      <td>0.257096</td>\n",
       "      <td>0.241306</td>\n",
       "      <td>14833</td>\n",
       "      <td>3707</td>\n",
       "      <td>11126</td>\n",
       "      <td>AutoTabPFN_5_balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.496093</td>\n",
       "      <td>0.502746</td>\n",
       "      <td>0.484911</td>\n",
       "      <td>0.620441</td>\n",
       "      <td>0.628366</td>\n",
       "      <td>0.611233</td>\n",
       "      <td>0.505679</td>\n",
       "      <td>0.511103</td>\n",
       "      <td>0.499981</td>\n",
       "      <td>0.277313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.734765</td>\n",
       "      <td>0.743655</td>\n",
       "      <td>0.728616</td>\n",
       "      <td>0.248593</td>\n",
       "      <td>0.255428</td>\n",
       "      <td>0.241605</td>\n",
       "      <td>14833</td>\n",
       "      <td>3707</td>\n",
       "      <td>11126</td>\n",
       "      <td>TabPFN_5_balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.498294</td>\n",
       "      <td>0.507644</td>\n",
       "      <td>0.485639</td>\n",
       "      <td>0.600283</td>\n",
       "      <td>0.607704</td>\n",
       "      <td>0.593708</td>\n",
       "      <td>0.503240</td>\n",
       "      <td>0.507140</td>\n",
       "      <td>0.498043</td>\n",
       "      <td>0.316698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.694769</td>\n",
       "      <td>0.703280</td>\n",
       "      <td>0.685998</td>\n",
       "      <td>0.251462</td>\n",
       "      <td>0.263478</td>\n",
       "      <td>0.242307</td>\n",
       "      <td>14833</td>\n",
       "      <td>3707</td>\n",
       "      <td>11126</td>\n",
       "      <td>xgboost_sample_5_balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.493710</td>\n",
       "      <td>0.504085</td>\n",
       "      <td>0.488078</td>\n",
       "      <td>0.553024</td>\n",
       "      <td>0.559012</td>\n",
       "      <td>0.544962</td>\n",
       "      <td>0.489483</td>\n",
       "      <td>0.496544</td>\n",
       "      <td>0.481570</td>\n",
       "      <td>0.400593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603811</td>\n",
       "      <td>0.612860</td>\n",
       "      <td>0.593787</td>\n",
       "      <td>0.247117</td>\n",
       "      <td>0.256430</td>\n",
       "      <td>0.237820</td>\n",
       "      <td>14833</td>\n",
       "      <td>3707</td>\n",
       "      <td>11126</td>\n",
       "      <td>lasso_sample_10_balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.492480</td>\n",
       "      <td>0.499814</td>\n",
       "      <td>0.483255</td>\n",
       "      <td>0.705589</td>\n",
       "      <td>0.712491</td>\n",
       "      <td>0.696772</td>\n",
       "      <td>0.484978</td>\n",
       "      <td>0.491905</td>\n",
       "      <td>0.478579</td>\n",
       "      <td>0.102239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.906615</td>\n",
       "      <td>0.911377</td>\n",
       "      <td>0.902121</td>\n",
       "      <td>0.248691</td>\n",
       "      <td>0.254699</td>\n",
       "      <td>0.241629</td>\n",
       "      <td>14833</td>\n",
       "      <td>3707</td>\n",
       "      <td>11126</td>\n",
       "      <td>AutoTabPFN_10_balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.493214</td>\n",
       "      <td>0.501598</td>\n",
       "      <td>0.482873</td>\n",
       "      <td>0.711454</td>\n",
       "      <td>0.716315</td>\n",
       "      <td>0.705501</td>\n",
       "      <td>0.481428</td>\n",
       "      <td>0.486026</td>\n",
       "      <td>0.476413</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.918210</td>\n",
       "      <td>0.921691</td>\n",
       "      <td>0.913196</td>\n",
       "      <td>0.249337</td>\n",
       "      <td>0.259614</td>\n",
       "      <td>0.240574</td>\n",
       "      <td>14833</td>\n",
       "      <td>3707</td>\n",
       "      <td>11126</td>\n",
       "      <td>TabPFN_10_balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.493374</td>\n",
       "      <td>0.502250</td>\n",
       "      <td>0.481466</td>\n",
       "      <td>0.741118</td>\n",
       "      <td>0.747494</td>\n",
       "      <td>0.735600</td>\n",
       "      <td>0.448679</td>\n",
       "      <td>0.454376</td>\n",
       "      <td>0.443467</td>\n",
       "      <td>0.025627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979507</td>\n",
       "      <td>0.981740</td>\n",
       "      <td>0.977407</td>\n",
       "      <td>0.248951</td>\n",
       "      <td>0.254278</td>\n",
       "      <td>0.238021</td>\n",
       "      <td>14833</td>\n",
       "      <td>3707</td>\n",
       "      <td>11126</td>\n",
       "      <td>xgboost_sample_10_balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.496342</td>\n",
       "      <td>0.502826</td>\n",
       "      <td>0.489242</td>\n",
       "      <td>0.529765</td>\n",
       "      <td>0.538824</td>\n",
       "      <td>0.523402</td>\n",
       "      <td>0.481395</td>\n",
       "      <td>0.486850</td>\n",
       "      <td>0.466451</td>\n",
       "      <td>0.448880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556714</td>\n",
       "      <td>0.564545</td>\n",
       "      <td>0.550394</td>\n",
       "      <td>0.247458</td>\n",
       "      <td>0.259200</td>\n",
       "      <td>0.239794</td>\n",
       "      <td>14833</td>\n",
       "      <td>3707</td>\n",
       "      <td>11126</td>\n",
       "      <td>lasso_sample_20_balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.495339</td>\n",
       "      <td>0.510633</td>\n",
       "      <td>0.487103</td>\n",
       "      <td>0.657925</td>\n",
       "      <td>0.666504</td>\n",
       "      <td>0.649801</td>\n",
       "      <td>0.500620</td>\n",
       "      <td>0.509259</td>\n",
       "      <td>0.493061</td>\n",
       "      <td>0.193418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.812691</td>\n",
       "      <td>0.820635</td>\n",
       "      <td>0.805485</td>\n",
       "      <td>0.249680</td>\n",
       "      <td>0.257630</td>\n",
       "      <td>0.240604</td>\n",
       "      <td>14833</td>\n",
       "      <td>3707</td>\n",
       "      <td>11126</td>\n",
       "      <td>AutoTabPFN_20_balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.495517</td>\n",
       "      <td>0.505443</td>\n",
       "      <td>0.485734</td>\n",
       "      <td>0.696218</td>\n",
       "      <td>0.703796</td>\n",
       "      <td>0.689719</td>\n",
       "      <td>0.488901</td>\n",
       "      <td>0.494416</td>\n",
       "      <td>0.482816</td>\n",
       "      <td>0.118694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888639</td>\n",
       "      <td>0.893057</td>\n",
       "      <td>0.883448</td>\n",
       "      <td>0.249284</td>\n",
       "      <td>0.261074</td>\n",
       "      <td>0.238163</td>\n",
       "      <td>14833</td>\n",
       "      <td>3707</td>\n",
       "      <td>11126</td>\n",
       "      <td>TabPFN_20_balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.496827</td>\n",
       "      <td>0.504207</td>\n",
       "      <td>0.486454</td>\n",
       "      <td>0.623947</td>\n",
       "      <td>0.633183</td>\n",
       "      <td>0.615260</td>\n",
       "      <td>0.503447</td>\n",
       "      <td>0.510428</td>\n",
       "      <td>0.496198</td>\n",
       "      <td>0.262746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.744293</td>\n",
       "      <td>0.751785</td>\n",
       "      <td>0.736982</td>\n",
       "      <td>0.249288</td>\n",
       "      <td>0.256946</td>\n",
       "      <td>0.238910</td>\n",
       "      <td>14833</td>\n",
       "      <td>3707</td>\n",
       "      <td>11126</td>\n",
       "      <td>xgboost_sample_20_balance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AUC   AUC_UCI   AUC_LCI       ACC   ACC_UCI   ACC_LCI  Macro_F1  \\\n",
       "0   0.490933  0.499805  0.478778  0.705521  0.711436  0.697701  0.487309   \n",
       "1   0.491894  0.500239  0.480308  0.689881  0.695193  0.683933  0.488936   \n",
       "2   0.495396  0.503295  0.486836  0.589227  0.594605  0.582876  0.500898   \n",
       "3   0.496205  0.506790  0.486198  0.607699  0.615133  0.605565  0.504705   \n",
       "4   0.496093  0.502746  0.484911  0.620441  0.628366  0.611233  0.505679   \n",
       "5   0.498294  0.507644  0.485639  0.600283  0.607704  0.593708  0.503240   \n",
       "6   0.493710  0.504085  0.488078  0.553024  0.559012  0.544962  0.489483   \n",
       "7   0.492480  0.499814  0.483255  0.705589  0.712491  0.696772  0.484978   \n",
       "8   0.493214  0.501598  0.482873  0.711454  0.716315  0.705501  0.481428   \n",
       "9   0.493374  0.502250  0.481466  0.741118  0.747494  0.735600  0.448679   \n",
       "10  0.496342  0.502826  0.489242  0.529765  0.538824  0.523402  0.481395   \n",
       "11  0.495339  0.510633  0.487103  0.657925  0.666504  0.649801  0.500620   \n",
       "12  0.495517  0.505443  0.485734  0.696218  0.703796  0.689719  0.488901   \n",
       "13  0.496827  0.504207  0.486454  0.623947  0.633183  0.615260  0.503447   \n",
       "\n",
       "    Macro_F1_UCI  Macro_F1_LCI  Sensitivity  ...  Specificity  \\\n",
       "0       0.493444      0.480732     0.106285  ...     0.905177   \n",
       "1       0.496889      0.483489     0.125708  ...     0.877854   \n",
       "2       0.508388      0.496095     0.337200  ...     0.673198   \n",
       "3       0.516875      0.494315     0.303480  ...     0.709060   \n",
       "4       0.511103      0.499981     0.277313  ...     0.734765   \n",
       "5       0.507140      0.498043     0.316698  ...     0.694769   \n",
       "6       0.496544      0.481570     0.400593  ...     0.603811   \n",
       "7       0.491905      0.478579     0.102239  ...     0.906615   \n",
       "8       0.486026      0.476413     0.090909  ...     0.918210   \n",
       "9       0.454376      0.443467     0.025627  ...     0.979507   \n",
       "10      0.486850      0.466451     0.448880  ...     0.556714   \n",
       "11      0.509259      0.493061     0.193418  ...     0.812691   \n",
       "12      0.494416      0.482816     0.118694  ...     0.888639   \n",
       "13      0.510428      0.496198     0.262746  ...     0.744293   \n",
       "\n",
       "    Specificity_UCI  Specificity_LCI       APR   APR_UCI   APR_LCI      N  \\\n",
       "0          0.908005         0.900284  0.248384  0.261198  0.239987  14833   \n",
       "1          0.884906         0.874051  0.246601  0.255733  0.236508  14833   \n",
       "2          0.681983         0.666645  0.248695  0.259715  0.241147  14833   \n",
       "3          0.713843         0.702477  0.248550  0.257096  0.241306  14833   \n",
       "4          0.743655         0.728616  0.248593  0.255428  0.241605  14833   \n",
       "5          0.703280         0.685998  0.251462  0.263478  0.242307  14833   \n",
       "6          0.612860         0.593787  0.247117  0.256430  0.237820  14833   \n",
       "7          0.911377         0.902121  0.248691  0.254699  0.241629  14833   \n",
       "8          0.921691         0.913196  0.249337  0.259614  0.240574  14833   \n",
       "9          0.981740         0.977407  0.248951  0.254278  0.238021  14833   \n",
       "10         0.564545         0.550394  0.247458  0.259200  0.239794  14833   \n",
       "11         0.820635         0.805485  0.249680  0.257630  0.240604  14833   \n",
       "12         0.893057         0.883448  0.249284  0.261074  0.238163  14833   \n",
       "13         0.751785         0.736982  0.249288  0.256946  0.238910  14833   \n",
       "\n",
       "    N_case  N_control                     method  \n",
       "0     3707      11126                 lasso_full  \n",
       "1     3707      11126               xgboost_full  \n",
       "2     3707      11126     lasso_sample_5_balance  \n",
       "3     3707      11126       AutoTabPFN_5_balance  \n",
       "4     3707      11126           TabPFN_5_balance  \n",
       "5     3707      11126   xgboost_sample_5_balance  \n",
       "6     3707      11126    lasso_sample_10_balance  \n",
       "7     3707      11126      AutoTabPFN_10_balance  \n",
       "8     3707      11126          TabPFN_10_balance  \n",
       "9     3707      11126  xgboost_sample_10_balance  \n",
       "10    3707      11126    lasso_sample_20_balance  \n",
       "11    3707      11126      AutoTabPFN_20_balance  \n",
       "12    3707      11126          TabPFN_20_balance  \n",
       "13    3707      11126  xgboost_sample_20_balance  \n",
       "\n",
       "[14 rows x 22 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([model.feature_names_in_, model[-1].coef_]).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
