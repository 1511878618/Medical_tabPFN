{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "\n",
    "- 数据集切分按照疾病、种族进行\n",
    "\n",
    "- 目前只针对蛋白组\n",
    "\n",
    "- 分种族训练\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "import pandas as pd\n",
    "import json\n",
    "from ppp_prediction.utils import load_data\n",
    "from ppp_prediction.model import fit_best_model\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ppp_prediction.plot.utils import save_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Basic Variables\n",
    "\n",
    "groupByVar = \"Ethnic\"  # Ethnic\n",
    "omicsName = \"Prot_meanImpute\"  # used omics Name\n",
    "phenoDefineVersion = \"Lancet_Digital_Health_2019\"  # used pheno version\n",
    "\n",
    "## cutoff\n",
    "Case_cutoff = 50  # only over this number of cases will be used as a phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dirs\n",
    "covariates_dir = dataDir / \"covariates.feather\"\n",
    "omicsDataDir = dataDir / f\"Prot/{omicsName}.feather\"\n",
    "\n",
    "phenoDefineDir = dataDir / f\"{phenoDefineVersion}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "covariates_df = pd.read_feather(covariates_dir)\n",
    "omicsData = pd.read_feather(omicsDataDir)\n",
    "print(\n",
    "    f\"Total {omicsData.shape[0]} samples and {omicsData.shape[1]} features with {omicsName}\"\n",
    ")\n",
    "diseaseList = list(phenoDefineDir.glob(\"*.feather\"))\n",
    "foundedPhenoFile = len(list(phenoDefineDir.glob(\"*.feather\")))\n",
    "print(f\"Founded Pheno Files: {foundedPhenoFile}\")\n",
    "covariates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupByVar used\n",
    "used_groupByVar = [\"White\", \"Asian\", \"Black\"]\n",
    "covariates_df[groupByVar].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all disease rate in Prot\n",
    "\n",
    "\n",
    "res_dict = {\n",
    "    \"event\": [],\n",
    "    \"incident\": [],\n",
    "    \"prevalent\": [],\n",
    "}\n",
    "for disease in tqdm(diseaseList, total=len(diseaseList), desc=\"Counting...\"):\n",
    "    df = pd.read_feather(disease).query(\"eid in @omicsData.eid\")\n",
    "\n",
    "    for col in [\"event\", \"incident\", \"prevalent\"]:\n",
    "        case = int(df[col].sum())\n",
    "        control = int(df.shape[0] - case)\n",
    "        rate = case / df.shape[0]\n",
    "        res_dict[col].append(\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"Phenotype\": [disease.stem],\n",
    "                    \"Case\": [case],\n",
    "                    \"Control\": [control],\n",
    "                    \"Rate\": [rate],\n",
    "                }\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df = (\n",
    "    pd.concat(res_dict[\"event\"])\n",
    "    .sort_values(\"Rate\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "incident_df = (\n",
    "    pd.concat(res_dict[\"incident\"])\n",
    "    .sort_values(\"Rate\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "prevalent_df = (\n",
    "    pd.concat(res_dict[\"prevalent\"])\n",
    "    .sort_values(\"Rate\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "event_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# histplot\n",
    "sns.histplot(data=event_df, x=\"Rate\", ax=ax1, bins=50)\n",
    "sns.histplot(data=incident_df, x=\"Rate\", ax=ax2, bins=50)\n",
    "sns.histplot(data=prevalent_df, x=\"Rate\", ax=ax3, bins=50)\n",
    "\n",
    "ax1.set_title(\"Event\")\n",
    "ax2.set_title(\"Incident\")\n",
    "ax3.set_title(\"Prevalent\")\n",
    "\n",
    "ax1.set_xlim(0, 0.2)\n",
    "ax2.set_xlim(0, 0.2)\n",
    "ax3.set_xlim(0, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# event_df =\n",
    "incident_df = incident_df.query(\"Case > @Case_cutoff\")\n",
    "prevalent_df = prevalent_df.query(\"Case > @Case_cutoff\")\n",
    "\n",
    "print(f\"Finnal Incident Phenotype: {incident_df.shape[0]}\")\n",
    "print(f\"Finnal Prevalent Phenotype: {prevalent_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Assoc\n",
    "\n",
    "1. For prevalence, by Cox \n",
    "2. For incident, by logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Cox\n",
    "\n",
    "## step1 extract all sample size over 30 and run cox for Prot \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incident_df\n",
    "\n",
    "\n",
    "# cross_corr_v3.py -q /home/xutingfeng/ukb/project/renji/data/phewas/NMR.pkl -k compative_disease.feather --cond /home/xutingfeng/ukb/project/renji/data/cov.feather  --key_cols disease survTime --event_key_cols disease --date_key_cols survTime --comprisk_order control CAD AAA -t 4 --cond_cols age --cat_cond_cols sex assessment_center any_lipids_drug -o test.tsv\n",
    "\n",
    "# parallel -q echo \"cross_corr_v3.py  -q data/phewas/{2}.pkl -k output/02-PSM/PSM_matched_data_1_{3}_{5}_{4}_{1}.feather    --key_cols incident survTime --date_key_cols survTime --event_key_cols incident --cond output/covs.feather --cond_cols age BMI  --cat_cond_cols assessment_center sex any_lipids_drug any_lower_pressure_drug smoking   -o output/01-phewas/PSM_matched_data_1_{3}_{5}_{4}/{1}/{2}.tsv --norm_x zscore \" ::: CAD AAA  ::: NMR ::: 2 3 ::: glm ::: nearest |bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 过滤表型\n",
    "\n",
    "保存Case 至少>50的疾病\n",
    "\n",
    "分种族过滤！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppp_prediction.model_v2.models import (\n",
    "    fit_best_model_v2,\n",
    "    fit_ensemble_model_simple_v2,\n",
    "    fit_lightgbm,\n",
    "    fit_xgboost,\n",
    ")\n",
    "\n",
    "\n",
    "def get_predict_v2_from_df(\n",
    "    model,\n",
    "    data,\n",
    "    x_var,\n",
    "):\n",
    "    \"\"\"\n",
    "    merge by idx\n",
    "    \"\"\"\n",
    "\n",
    "    no_na_data = data[x_var].dropna().copy()\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        no_na_data[\"pred\"] = model.predict_proba(no_na_data)[:, 1]\n",
    "    else:\n",
    "        no_na_data[\"pred\"] = model.predict(no_na_data)\n",
    "\n",
    "    return (\n",
    "        data[[]]\n",
    "        .merge(no_na_data[[\"pred\"]], left_index=True, right_index=True, how=\"left\")\n",
    "        .values.flatten()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from ppp_prediction.metrics import cal_binary_metrics\n",
    "\n",
    "\n",
    "# define a function to fit the model, save the result and collect the scores\n",
    "## parallel this function\n",
    "def fit_model_and_save_result(\n",
    "    total_df,  # first col should be eid\n",
    "    label_df,  # first col should be eid\n",
    "    save_dir,\n",
    "    # asssoc_df=None, # used to sort and get top features to downsample, if None then will do assoc\n",
    "    feature_rank_list=None,  # used to downsample the features\n",
    "    min_class_number_cutoff={\"train\": 30, \"validation\": 10, \"test\": 10},\n",
    "    train_test_split_ratio=0.7,\n",
    "    seed=1234,\n",
    "    device=\"cuda\",\n",
    "    topk_list=[5, 10, 20, 50, 100],\n",
    "):\n",
    "    \"\"\"\n",
    "    1. merge the total_df and disease_df\n",
    "    2. check label_df sum is over min_class_number_cutoff; if not return None, and print the error\n",
    "    3. fit the models: 1) full lasso, 2) full xgboost, 3) sample lasso, 4) sample xgboost, 5) sample AutoTabPFN, 6) TabPFN\n",
    "    4. save the results: 1) model, 2) scores of total_df, 3) metrics of models\n",
    "    \"\"\"\n",
    "    # step1: merge and check\n",
    "\n",
    "    ## check the first column\n",
    "    if total_df.columns[0] != \"eid\":\n",
    "        raise ValueError(\"total_df first column should be eid\")\n",
    "    if label_df.columns[0] != \"eid\":\n",
    "        raise ValueError(\"label_df first column should be eid\")\n",
    "\n",
    "    features = total_df.columns[1:].tolist()\n",
    "    label = label_df.columns[1]\n",
    "\n",
    "    ## merge\n",
    "    merged_df = pd.merge(total_df, label_df, on=\"eid\", how=\"inner\")\n",
    "    print(\n",
    "        f\"Found merged samples: {merged_df.shape[0]} while, label_df: {label_df.shape[0]} and total_df: {total_df.shape[0]}\"\n",
    "    )\n",
    "\n",
    "    # step2: fit the model\n",
    "    ## step2.1 Train Test Split\n",
    "    train_df, test_df = train_test_split(\n",
    "        merged_df, test_size=1 - train_test_split_ratio, random_state=seed\n",
    "    )\n",
    "    train_df, val_df = train_test_split(train_df, test_size=0.3, random_state=seed)\n",
    "\n",
    "    score_df = pd.concat(\n",
    "        [\n",
    "            train_df[[\"eid\", label]].copy().assign(Type=\"train\"),\n",
    "            val_df[[\"eid\", label]].copy().assign(Type=\"validation\"),\n",
    "            test_df[[\"eid\", label]].copy().assign(Type=\"test\"),\n",
    "        ]\n",
    "    )\n",
    "    ## step2.2 check the min_class_number\n",
    "    for min_class_number_check_key in [\"train\", \"validation\", \"test\"]:\n",
    "        if min_class_number_check_key == \"train\":\n",
    "            to_check_df = train_df\n",
    "        elif min_class_number_check_key == \"validation\":\n",
    "            to_check_df = val_df\n",
    "        elif min_class_number_check_key == \"test\":\n",
    "            to_check_df = test_df\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"min_class_number_check_key should be in ['train', 'validation', 'test']\"\n",
    "            )\n",
    "        min_class_number = min(to_check_df[label].value_counts())\n",
    "        # the min class number and class name\n",
    "        min_class_name = to_check_df[label].value_counts().idxmin()\n",
    "        if min_class_number < min_class_number_cutoff[min_class_number_check_key]:\n",
    "            print(\n",
    "                f\"Error: {min_class_number_check_key} {min_class_name} has only {min_class_number} samples, less than {min_class_number_cutoff[min_class_number_check_key]}\"\n",
    "            )\n",
    "            return None\n",
    "    print(\n",
    "        f\"Train data have {train_df.shape[0]} samples with {train_df[label].sum():.0f} cases\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Validation data have {val_df.shape[0]} samples with {val_df[label].sum():.0f} cases\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Test data have {test_df.shape[0]} samples with {test_df[label].sum():.0f} cases\"\n",
    "    )\n",
    "\n",
    "    ## check\n",
    "    train_meta_info = {}\n",
    "    ## step2.4 fit the models\n",
    "    modelSaveDir = save_dir / \"models\"\n",
    "    modelSaveDir.mkdir(parents=True, exist_ok=True)\n",
    "    ### 1) Lasso full\n",
    "    lasso_full_savedir = modelSaveDir / \"lasso_full.pkl\"\n",
    "    if lasso_full_savedir.exists():\n",
    "        lasso_full = pickle.load(open(lasso_full_savedir, \"rb\"))\n",
    "        # print(f\"lasso_full loaded\")\n",
    "\n",
    "    else:\n",
    "        lasso_engine = \"cuml\" if device == \"cuda\" else \"sklearn\"\n",
    "        print(merged_df.shape)\n",
    "        if merged_df.shape[0] < 5000:\n",
    "            lasso_engine = \"sklearn\"\n",
    "        print(f\"lasso_full start with engine {lasso_engine}\")\n",
    "        (lasso_full, *_) = fit_best_model(\n",
    "            train_df=train_df,\n",
    "            test_df=val_df,\n",
    "            X_var=features,\n",
    "            y_var=label,\n",
    "            method_list=\"Lasso\",\n",
    "            cv=5,\n",
    "            engine=lasso_engine,\n",
    "        )\n",
    "\n",
    "        pickle.dump(lasso_full, open(lasso_full_savedir, \"wb\"))\n",
    "\n",
    "    score_df[\"lasso_full\"] = get_predict_v2_from_df(lasso_full, total_df, features)\n",
    "    # return lasso_full, score_df\n",
    "    train_meta_info[f\"lasso_full\"] = {\n",
    "        \"train_case\": train_df[label].sum(),\n",
    "        \"train_control\": train_df.shape[0] - train_df[label].sum(),\n",
    "    }\n",
    "    if isinstance(feature_rank_list, str):\n",
    "        if feature_rank_list == \"assoc\":\n",
    "            # feature_rank_list = lasso_full.coef_.argsort()\n",
    "            raise NotImplementedError(\"assoc not implemented\")\n",
    "            # pass\n",
    "        elif feature_rank_list == \"lasso\":\n",
    "            feature_rank_df = pd.DataFrame(\n",
    "                [lasso_full.feature_names_in_, lasso_full[-1].coef_]\n",
    "            ).T\n",
    "            feature_rank_df.columns = [\"feature\", \"coef\"]\n",
    "            feature_rank_df[\"abs_coef\"] = feature_rank_df[\"coef\"].abs()\n",
    "            feature_rank_df = feature_rank_df.sort_values(\"abs_coef\", ascending=False)\n",
    "            feature_rank_list = feature_rank_df[\"feature\"].tolist()\n",
    "            feature_rank_df.to_csv(\n",
    "                save_dir / \"feature_rank_lasso_full.csv\", index=False\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"feature_rank_list should be in ['assoc', 'lasso'] or a list of features with the first one is the most important\"\n",
    "            )\n",
    "    elif isinstance(feature_rank_list, list):\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"feature_rank_list should be in ['assoc', 'lasso'] or a list of features with the first one is the most important\"\n",
    "        )\n",
    "\n",
    "    del lasso_full\n",
    "\n",
    "    # xgboost full\n",
    "    xgboot_full_savedir = modelSaveDir / \"xgboost_full.pkl\"\n",
    "    if (modelSaveDir / \"xgboost_full.pkl\").exists():\n",
    "        print(f\"xgboost_full loaded\")\n",
    "        xgboost_full_tuned = pickle.load(open(xgboot_full_savedir, \"rb\"))\n",
    "    else:\n",
    "\n",
    "        xgboost_full_tuned, *_ = fit_xgboost(\n",
    "            train=train_df,\n",
    "            xvar=features,\n",
    "            label=label,\n",
    "            tuning=True,\n",
    "            tune_config={\"max_iter\": 100},\n",
    "        )\n",
    "        pickle.dump(xgboost_full_tuned, open(xgboot_full_savedir, \"wb\"))\n",
    "    score_df[\"xgboost_full\"] = get_predict_v2_from_df(\n",
    "        xgboost_full_tuned, total_df, features\n",
    "    )\n",
    "    train_meta_info[f\"xgboost_full\"] = {\n",
    "        \"train_case\": train_df[label].sum(),\n",
    "        \"train_control\": train_df.shape[0] - train_df[label].sum(),\n",
    "    }\n",
    "\n",
    "    del xgboost_full_tuned\n",
    "\n",
    "    for strata in [\"balance\", \"random\"]:  # balance or random\n",
    "        if strata == \"balance\":\n",
    "            disease_train_case = train_df.query(f\"{label} == 1\")\n",
    "            disease_train_control = train_df.query(f\"{label} == 0\").sample(\n",
    "                n=disease_train_case.shape[0], random_state=seed\n",
    "            )\n",
    "            disease_train_sample = pd.concat(\n",
    "                [disease_train_case, disease_train_control]\n",
    "            )\n",
    "        elif strata == \"random\":\n",
    "            if train_df.shape[0] > 10000:\n",
    "                disease_train_sample = train_df.sample(n=10000, random_state=seed)\n",
    "            else:\n",
    "                disease_train_sample = train_df  # TODO: Anno this with no sample\n",
    "\n",
    "        for topk in topk_list:\n",
    "            sig_features = feature_rank_list[:topk]\n",
    "\n",
    "            suffix_name = f\"{topk}_{strata}\"\n",
    "\n",
    "            print(suffix_name)\n",
    "\n",
    "            strata_topk_save_dir = modelSaveDir / f\"{topk}/{strata}\"\n",
    "            strata_topk_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            X_train = disease_train_sample[sig_features]\n",
    "            y_train = disease_train_sample[label]\n",
    "\n",
    "            lasso_sample_topk_savedir = strata_topk_save_dir / f\"lasso_sample.pkl\"\n",
    "            if lasso_sample_topk_savedir.exists():\n",
    "                lasso_sample = pickle.load(open(lasso_sample_topk_savedir, \"rb\"))\n",
    "                print(f\"lasso_sample_{suffix_name} loaded\")\n",
    "            else:\n",
    "                try:\n",
    "                    lasso_engine = \"cuml\" if device == \"cuda\" else \"sklearn\"\n",
    "                    if X_train.shape[0] < 5000:\n",
    "                        lasso_engine = \"sklearn\"\n",
    "                    print(f\"lasso_full start with engine {lasso_engine}\")\n",
    "\n",
    "                    (lasso_sample, *_) = fit_best_model(\n",
    "                        train_df=disease_train_sample,\n",
    "                        test_df=val_df,\n",
    "                        X_var=sig_features,\n",
    "                        y_var=label,\n",
    "                        method_list=\"Lasso\",\n",
    "                        cv=5,\n",
    "                        engine=lasso_engine,\n",
    "                    )\n",
    "                    pickle.dump(\n",
    "                        lasso_sample,\n",
    "                        open(strata_topk_save_dir / f\"lasso_sample.pkl\", \"wb\"),\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"lasso_sample_{topk} failed and erros: {e}\")\n",
    "\n",
    "            score_df[f\"lasso_sample_{suffix_name}\"] = get_predict_v2_from_df(\n",
    "                lasso_sample, total_df, sig_features\n",
    "            )\n",
    "            train_meta_info[f\"lasso_sample_{suffix_name}\"] = {\n",
    "                \"train_case\": disease_train_sample[label].sum(),\n",
    "                \"train_control\": disease_train_sample.shape[0]\n",
    "                - disease_train_sample[label].sum(),\n",
    "            }\n",
    "\n",
    "            del lasso_sample\n",
    "\n",
    "            from tabpfn_extensions.post_hoc_ensembles.sklearn_interface import (\n",
    "                AutoTabPFNClassifier,\n",
    "            )\n",
    "\n",
    "            AutoTabPFN_topk_savedir = strata_topk_save_dir / f\"AutoTabPFN.pkl\"\n",
    "            if AutoTabPFN_topk_savedir.exists():\n",
    "                AutoTabPFN = pickle.load(open(AutoTabPFN_topk_savedir, \"rb\"))\n",
    "                print(f\"AutoTabPFN_{topk} loaded\")\n",
    "            else:\n",
    "\n",
    "                try:\n",
    "                    AutoTabPFN = AutoTabPFNClassifier(\n",
    "                        max_time=120, device=\"cuda\" if device == \"cuda\" else \"cpu\"\n",
    "                    )  # 120 seconds tuning time\n",
    "                    AutoTabPFN.fit(X_train, y_train)\n",
    "                    pickle.dump(\n",
    "                        AutoTabPFN, open(strata_topk_save_dir / f\"AutoTabPFN.pkl\", \"wb\")\n",
    "                    )\n",
    "                except:\n",
    "                    print(f\"AutoTabPFN_{topk} failed\")\n",
    "\n",
    "            # score_df[\"AutoTabPFN\"] = AutoTabPFN.predict_proba(X_held_out_test)[:, 1]\n",
    "            score_df[f\"AutoTabPFN_{suffix_name}\"] = AutoTabPFN.predict_proba(\n",
    "                total_df[sig_features]\n",
    "            )[:, 1]\n",
    "            train_meta_info[f\"AutoTabPFN_{suffix_name}\"] = {\n",
    "                \"train_case\": disease_train_sample[label].sum(),\n",
    "                \"train_control\": disease_train_sample.shape[0]\n",
    "                - disease_train_sample[label].sum(),\n",
    "            }\n",
    "\n",
    "            del AutoTabPFN\n",
    "            try:\n",
    "                from tabpfn import TabPFNClassifier\n",
    "\n",
    "                TabPFN_topk_savedir = strata_topk_save_dir / f\"TabPFN{topk}.pkl\"\n",
    "                if TabPFN_topk_savedir.exists():\n",
    "                    TabPFN = pickle.load(open(TabPFN_topk_savedir, \"rb\"))\n",
    "                    print(f\"TabPFN_{topk} loaded\")\n",
    "                else:\n",
    "\n",
    "                    TabPFN = TabPFNClassifier(\n",
    "                        device=\"cuda:0\" if device == \"cuda\" else \"cpu\",\n",
    "                        ignore_pretraining_limits=True,\n",
    "                    )\n",
    "                    TabPFN.fit(X_train, y_train)\n",
    "                    pickle.dump(\n",
    "                        TabPFN, open(strata_topk_save_dir / f\"TabPFN.pkl\", \"wb\")\n",
    "                    )\n",
    "                # score_df[\"AutoTabPFN\"] = AutoTabPFN.predict_proba(X_held_out_test)[:, 1]\n",
    "                score_df[f\"TabPFN_{suffix_name}\"] = TabPFN.predict_proba(\n",
    "                    total_df[sig_features]\n",
    "                )[:, 1]\n",
    "                train_meta_info[f\"TabPFN_{suffix_name}\"] = {\n",
    "                    \"train_case\": disease_train_sample[label].sum(),\n",
    "                    \"train_control\": disease_train_sample.shape[0]\n",
    "                    - disease_train_sample[label].sum(),\n",
    "                }\n",
    "                del TabPFN\n",
    "            except:\n",
    "                print(f\"TabPFN {topk} failed\")\n",
    "\n",
    "            # xgboost sampled\n",
    "            xgboost_sample_savedir = strata_topk_save_dir / f\"xgboost_sample.pkl\"\n",
    "            if xgboost_sample_savedir.exists():\n",
    "                xgboost_sample_tuned = pickle.load(open(xgboost_sample_savedir, \"rb\"))\n",
    "                print(f\"xgboost_sample_{topk} loaded\")\n",
    "            else:\n",
    "                try:\n",
    "                    xgboost_sample_tuned, *_ = fit_xgboost(\n",
    "                        train=disease_train_sample,\n",
    "                        xvar=sig_features,\n",
    "                        label=label,\n",
    "                        tuning=True,\n",
    "                        tune_config={\"max_iter\": 100},\n",
    "                    )\n",
    "                    pickle.dump(\n",
    "                        xgboost_sample_tuned,\n",
    "                        open(strata_topk_save_dir / f\"xgboost_sample.pkl\", \"wb\"),\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"xgboost_sample_{topk} failed\")\n",
    "\n",
    "            score_df[f\"xgboost_sample_{suffix_name}\"] = get_predict_v2_from_df(\n",
    "                xgboost_sample_tuned, total_df, sig_features\n",
    "            )\n",
    "            train_meta_info[f\"xgboost_sample_{suffix_name}\"] = {\n",
    "                \"train_case\": disease_train_sample[label].sum(),\n",
    "                \"train_control\": disease_train_sample.shape[0]\n",
    "                - disease_train_sample[label].sum(),\n",
    "            }\n",
    "\n",
    "            del xgboost_sample_tuned\n",
    "\n",
    "    score_df.to_feather(save_dir / \"held_out_test.feather\")\n",
    "    pickle.dump(train_meta_info, open(save_dir / \"train_meta_info.pkl\", \"wb\"))\n",
    "    metrics_list = []\n",
    "    for key in score_df.columns[3:]:  # eid label Type\n",
    "        to_cal_df = (\n",
    "            score_df.query(\"Type == 'test'\")[[\"eid\", label, key]].copy().dropna()\n",
    "        )\n",
    "        res = cal_binary_metrics(\n",
    "            to_cal_df[label], to_cal_df[key], n_resamples=30, ci=True\n",
    "        )\n",
    "        # res = run_cox(to_cal_df, var=key, E=E, T=T, ci=True, n_resamples=100)\n",
    "        res[\"method\"] = key\n",
    "        res.update(train_meta_info[key])\n",
    "        metrics_list.append(res)\n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "    metrics_df.to_csv(save_dir / \"metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultDir = outputDir / \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for disease in diseaseList:\n",
    "for disease in [Path(\"V1/data/Lancet_Digital_Health_2019/hypertension.feather\")]:\n",
    "    diseaseName = disease.stem\n",
    "    # for c_groupbyVar in used_groupByVar:\n",
    "    for c_groupbyVar in [\"White\"]:\n",
    "        # for label in [\"prevalent\", \"incident\"]:\n",
    "        c_groupbyVar_eids = covariates_df.query(f\"{groupByVar} == @c_groupbyVar\").eid\n",
    "        for label in [\"incident\", \"prevalent\"]:\n",
    "            print(f\"Currently, Running {label} {diseaseName} and {c_groupbyVar}\")\n",
    "            label_df = pd.read_feather(disease).query(\"eid in @omicsData.eid\")\n",
    "            res = fit_model_and_save_result(\n",
    "                total_df=omicsData.query(f\"eid in @c_groupbyVar_eids\"),\n",
    "                label_df=label_df[[\"eid\", label]],\n",
    "                save_dir=resultDir / f\"{diseaseName}/{c_groupbyVar}/{label}\",\n",
    "                # feature_rank_list=fake_rank_list,  # currently use the fake rank list, better use assoc on whole set or run assoc on the train set\n",
    "                device=\"cuda\",\n",
    "                topk_list=[5, 10, 20, 50, 100],\n",
    "            )\n",
    "            break\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score_df = pd.read_feather(\"V1/output/test/hypertension/Asian/incident/held_out_test.feather\")\n",
    "metrics_list = []\n",
    "for key in score_df.columns[3:]:\n",
    "    to_cal_df = score_df.query(\"Type == 'test'\")[[\"eid\", label, key]].copy().dropna()\n",
    "    res = cal_binary_metrics(\n",
    "        to_cal_df[label], to_cal_df[key], n_resamples=30, ci=True\n",
    "    )\n",
    "    # res = run_cox(to_cal_df, var=key, E=E, T=T, ci=True, n_resamples=100)\n",
    "    res[\"method\"] = key\n",
    "    metrics_list.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metrics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([model.feature_names_in_, model[-1].coef_]).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
