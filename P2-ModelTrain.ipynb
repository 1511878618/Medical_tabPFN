{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "\n",
    "- 数据集切分按照疾病、种族进行\n",
    "\n",
    "- 目前只针对蛋白组\n",
    "\n",
    "- 分种族训练\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "2025-02-19 11:44:56,426\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-02-19 11:44:56,552\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-02-19 11:44:56,626\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from config import *\n",
    "import pandas as pd\n",
    "import json\n",
    "from ppp_prediction.utils import load_data\n",
    "from ppp_prediction.model import fit_best_model\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ppp_prediction.plot.utils import save_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Basic Variables\n",
    "\n",
    "groupByVar = \"Ethnic\"  # Ethnic\n",
    "omicsName = \"Prot_meanImpute\"  # used omics Name\n",
    "phenoDefineVersion = \"Lancet_Digital_Health_2019\"  # used pheno version\n",
    "\n",
    "## cutoff\n",
    "Case_cutoff = 50  # only over this number of cases will be used as a phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dirs\n",
    "covariates_dir = dataDir / \"covariates.feather\"\n",
    "omicsDataDir = dataDir / f\"Prot/{omicsName}.feather\"\n",
    "\n",
    "phenoDefineDir = dataDir / f\"{phenoDefineVersion}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 53021 samples and 2912 features with Prot_meanImpute\n",
      "Founded Pheno Files: 169\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eid</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>BSA</th>\n",
       "      <th>age</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>...</th>\n",
       "      <th>drug_ldl</th>\n",
       "      <th>drug_hdl</th>\n",
       "      <th>drug_tc</th>\n",
       "      <th>drug_sbp</th>\n",
       "      <th>drug_dbp</th>\n",
       "      <th>genotype_array</th>\n",
       "      <th>assessment_center</th>\n",
       "      <th>ancestry</th>\n",
       "      <th>ancestry_high_confi</th>\n",
       "      <th>Ethnic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000017</td>\n",
       "      <td>1.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>89.5</td>\n",
       "      <td>2.067876</td>\n",
       "      <td>56.0</td>\n",
       "      <td>-11.3690</td>\n",
       "      <td>3.56718</td>\n",
       "      <td>-1.975530</td>\n",
       "      <td>0.213937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>EUR</td>\n",
       "      <td>EUR</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>113.9</td>\n",
       "      <td>2.359755</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-12.1620</td>\n",
       "      <td>2.77470</td>\n",
       "      <td>0.175048</td>\n",
       "      <td>2.554930</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>EUR</td>\n",
       "      <td>EUR</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000038</td>\n",
       "      <td>1.0</td>\n",
       "      <td>179.5</td>\n",
       "      <td>112.2</td>\n",
       "      <td>2.365252</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-12.8698</td>\n",
       "      <td>6.41566</td>\n",
       "      <td>-5.106100</td>\n",
       "      <td>-1.296310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>EUR</td>\n",
       "      <td>EUR</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000042</td>\n",
       "      <td>1.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>77.1</td>\n",
       "      <td>1.902476</td>\n",
       "      <td>60.0</td>\n",
       "      <td>72.9437</td>\n",
       "      <td>-109.21600</td>\n",
       "      <td>74.692200</td>\n",
       "      <td>17.863400</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>SAS</td>\n",
       "      <td>SAS</td>\n",
       "      <td>Asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.805547</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-10.7174</td>\n",
       "      <td>5.77507</td>\n",
       "      <td>0.620341</td>\n",
       "      <td>0.505251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>EUR</td>\n",
       "      <td>EUR</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502404</th>\n",
       "      <td>6024086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.940218</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-11.1845</td>\n",
       "      <td>4.08367</td>\n",
       "      <td>-0.006942</td>\n",
       "      <td>-0.325017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>EUR</td>\n",
       "      <td>EUR</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502405</th>\n",
       "      <td>6024098</td>\n",
       "      <td>1.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>81.3</td>\n",
       "      <td>1.976592</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-13.3426</td>\n",
       "      <td>2.56658</td>\n",
       "      <td>-0.076882</td>\n",
       "      <td>6.048100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>EUR</td>\n",
       "      <td>EUR</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502406</th>\n",
       "      <td>6024103</td>\n",
       "      <td>1.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>111.3</td>\n",
       "      <td>2.404458</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-12.2113</td>\n",
       "      <td>4.22902</td>\n",
       "      <td>-2.629170</td>\n",
       "      <td>4.489250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>EUR</td>\n",
       "      <td>EUR</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502407</th>\n",
       "      <td>6024110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>73.2</td>\n",
       "      <td>1.897103</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-10.5527</td>\n",
       "      <td>6.84118</td>\n",
       "      <td>-2.149580</td>\n",
       "      <td>-0.825010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>EUR</td>\n",
       "      <td>EUR</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502408</th>\n",
       "      <td>6024122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>91.6</td>\n",
       "      <td>2.067527</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-11.4469</td>\n",
       "      <td>2.66226</td>\n",
       "      <td>-5.098050</td>\n",
       "      <td>0.441097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>EUR</td>\n",
       "      <td>EUR</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>502409 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            eid  sex  height  weight       BSA   age      PC1        PC2  \\\n",
       "0       1000017  1.0   172.0    89.5  2.067876  56.0 -11.3690    3.56718   \n",
       "1       1000025  1.0   176.0   113.9  2.359755  62.0 -12.1620    2.77470   \n",
       "2       1000038  1.0   179.5   112.2  2.365252  60.0 -12.8698    6.41566   \n",
       "3       1000042  1.0   169.0    77.1  1.902476  60.0  72.9437 -109.21600   \n",
       "4       1000056  0.0   163.0    72.0  1.805547  65.0 -10.7174    5.77507   \n",
       "...         ...  ...     ...     ...       ...   ...      ...        ...   \n",
       "502404  6024086  0.0   154.0    88.0  1.940218  66.0 -11.1845    4.08367   \n",
       "502405  6024098  1.0   173.0    81.3  1.976592  68.0 -13.3426    2.56658   \n",
       "502406  6024103  1.0   187.0   111.3  2.404458  61.0 -12.2113    4.22902   \n",
       "502407  6024110  1.0   177.0    73.2  1.897103  66.0 -10.5527    6.84118   \n",
       "502408  6024122  0.0   168.0    91.6  2.067527  66.0 -11.4469    2.66226   \n",
       "\n",
       "              PC3        PC4  ...  drug_ldl  drug_hdl  drug_tc  drug_sbp  \\\n",
       "0       -1.975530   0.213937  ...       0.0       0.0      0.0       1.0   \n",
       "1        0.175048   2.554930  ...       1.0       0.0      1.0       1.0   \n",
       "2       -5.106100  -1.296310  ...       0.0       0.0      0.0       1.0   \n",
       "3       74.692200  17.863400  ...       1.0       0.0      1.0       1.0   \n",
       "4        0.620341   0.505251  ...       0.0       0.0      0.0       0.0   \n",
       "...           ...        ...  ...       ...       ...      ...       ...   \n",
       "502404  -0.006942  -0.325017  ...       0.0       0.0      0.0       0.0   \n",
       "502405  -0.076882   6.048100  ...       0.0       1.0      0.0       1.0   \n",
       "502406  -2.629170   4.489250  ...       0.0       0.0      0.0       1.0   \n",
       "502407  -2.149580  -0.825010  ...       0.0       0.0      0.0       0.0   \n",
       "502408  -5.098050   0.441097  ...       0.0       0.0      0.0       0.0   \n",
       "\n",
       "        drug_dbp  genotype_array  assessment_center  ancestry  \\\n",
       "0            1.0               1                  1       EUR   \n",
       "1            1.0               2                  2       EUR   \n",
       "2            1.0               1                  3       EUR   \n",
       "3            1.0               2                  3       SAS   \n",
       "4            0.0               2                  4       EUR   \n",
       "...          ...             ...                ...       ...   \n",
       "502404       0.0               2                  8       EUR   \n",
       "502405       1.0               2                  9       EUR   \n",
       "502406       1.0               2                 20       EUR   \n",
       "502407       0.0               2                 11       EUR   \n",
       "502408       0.0               2                  2       EUR   \n",
       "\n",
       "        ancestry_high_confi  Ethnic  \n",
       "0                       EUR   White  \n",
       "1                       EUR   White  \n",
       "2                       EUR   White  \n",
       "3                       SAS   Asian  \n",
       "4                       EUR   White  \n",
       "...                     ...     ...  \n",
       "502404                  EUR   White  \n",
       "502405                  EUR   White  \n",
       "502406                  EUR   White  \n",
       "502407                  EUR   White  \n",
       "502408                  EUR   White  \n",
       "\n",
       "[502409 rows x 51 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "covariates_df = pd.read_feather(covariates_dir)\n",
    "omicsData = pd.read_feather(omicsDataDir)\n",
    "print(\n",
    "    f\"Total {omicsData.shape[0]} samples and {omicsData.shape[1]} features with {omicsName}\"\n",
    ")\n",
    "diseaseList = list(phenoDefineDir.glob(\"*.feather\"))\n",
    "foundedPhenoFile = len(list(phenoDefineDir.glob(\"*.feather\")))\n",
    "print(f\"Founded Pheno Files: {foundedPhenoFile}\")\n",
    "covariates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ethnic\n",
       "White      472610\n",
       "Asian        9879\n",
       "Black        8058\n",
       "Other        7335\n",
       "Mixed        2954\n",
       "Chinese      1573\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# groupByVar used\n",
    "used_groupByVar = [\"White\", \"Asian\", \"Black\"]\n",
    "covariates_df[groupByVar].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting...:  50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                            | 85/169 [00:30<00:29,  2.83it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m\n\u001b[1;32m      4\u001b[0m res_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincident\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprevalent\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m      8\u001b[0m }\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m disease \u001b[38;5;129;01min\u001b[39;00m tqdm(diseaseList, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(diseaseList), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCounting...\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 10\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_feather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdisease\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meid in @omicsData.eid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincident\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprevalent\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m     13\u001b[0m         case \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(df[col]\u001b[38;5;241m.\u001b[39msum())\n",
      "File \u001b[0;32m/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/pandas/io/feather_format.py:124\u001b[0m, in \u001b[0;36mread_feather\u001b[0;34m(path, columns, use_threads, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m    121\u001b[0m     path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m, storage_options\u001b[38;5;241m=\u001b[39mstorage_options, is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    122\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_pyarrow_string_dtype():\n\u001b[0;32m--> 124\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfeather\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_feather\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43muse_threads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m feather\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[1;32m    129\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle, columns\u001b[38;5;241m=\u001b[39mcolumns, use_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(use_threads)\n\u001b[1;32m    130\u001b[0m     )\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_backend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy_nullable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/pyarrow/feather.py:226\u001b[0m, in \u001b[0;36mread_feather\u001b[0;34m(source, columns, use_threads, memory_map, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread_feather\u001b[39m(source, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, use_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    200\u001b[0m                  memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    201\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m    Read a pandas.DataFrame from Feather format. To read as pyarrow.Table use\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m    feather.read_table.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03m        The contents of the Feather file as a pandas.DataFrame\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_threads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/pyarrow/array.pxi:883\u001b[0m, in \u001b[0;36mpyarrow.lib._PandasConvertible.to_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/pyarrow/table.pxi:4251\u001b[0m, in \u001b[0;36mpyarrow.lib.Table._to_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/pyarrow/pandas_compat.py:777\u001b[0m, in \u001b[0;36mtable_to_dataframe\u001b[0;34m(options, table, categories, ignore_metadata, types_mapper)\u001b[0m\n\u001b[1;32m    775\u001b[0m _check_data_column_metadata_consistency(all_columns)\n\u001b[1;32m    776\u001b[0m columns \u001b[38;5;241m=\u001b[39m _deserialize_column_index(table, all_columns, column_indexes)\n\u001b[0;32m--> 777\u001b[0m blocks \u001b[38;5;241m=\u001b[39m \u001b[43m_table_to_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mext_columns_dtypes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n\u001b[1;32m    780\u001b[0m mgr \u001b[38;5;241m=\u001b[39m BlockManager(blocks, axes)\n",
      "File \u001b[0;32m/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/pyarrow/pandas_compat.py:1131\u001b[0m, in \u001b[0;36m_table_to_blocks\u001b[0;34m(options, block_table, categories, extension_columns)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_table_to_blocks\u001b[39m(options, block_table, categories, extension_columns):\n\u001b[1;32m   1127\u001b[0m     \u001b[38;5;66;03m# Part of table_to_blockmanager\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m# Convert an arrow table to Block from the internal pandas API\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     columns \u001b[38;5;241m=\u001b[39m block_table\u001b[38;5;241m.\u001b[39mcolumn_names\n\u001b[0;32m-> 1131\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable_to_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextension_columns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_reconstruct_block(item, columns, extension_columns)\n\u001b[1;32m   1134\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# show all disease rate in Prot\n",
    "\n",
    "\n",
    "res_dict = {\n",
    "    \"event\": [],\n",
    "    \"incident\": [],\n",
    "    \"prevalent\": [],\n",
    "}\n",
    "for disease in tqdm(diseaseList, total=len(diseaseList), desc=\"Counting...\"):\n",
    "    df = pd.read_feather(disease).query(\"eid in @omicsData.eid\")\n",
    "\n",
    "    for col in [\"event\", \"incident\", \"prevalent\"]:\n",
    "        case = int(df[col].sum())\n",
    "        control = int(df.shape[0] - case)\n",
    "        rate = case / df.shape[0]\n",
    "        res_dict[col].append(\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"Phenotype\": [disease.stem],\n",
    "                    \"Case\": [case],\n",
    "                    \"Control\": [control],\n",
    "                    \"Rate\": [rate],\n",
    "                }\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df = (\n",
    "    pd.concat(res_dict[\"event\"])\n",
    "    .sort_values(\"Rate\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "incident_df = (\n",
    "    pd.concat(res_dict[\"incident\"])\n",
    "    .sort_values(\"Rate\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "prevalent_df = (\n",
    "    pd.concat(res_dict[\"prevalent\"])\n",
    "    .sort_values(\"Rate\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "event_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# histplot\n",
    "sns.histplot(data=event_df, x=\"Rate\", ax=ax1, bins=50)\n",
    "sns.histplot(data=incident_df, x=\"Rate\", ax=ax2, bins=50)\n",
    "sns.histplot(data=prevalent_df, x=\"Rate\", ax=ax3, bins=50)\n",
    "\n",
    "ax1.set_title(\"Event\")\n",
    "ax2.set_title(\"Incident\")\n",
    "ax3.set_title(\"Prevalent\")\n",
    "\n",
    "ax1.set_xlim(0, 0.2)\n",
    "ax2.set_xlim(0, 0.2)\n",
    "ax3.set_xlim(0, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finnal Incident Phenotype: 13\n",
      "Finnal Prevalent Phenotype: 6\n"
     ]
    }
   ],
   "source": [
    "# event_df =\n",
    "incident_df = incident_df.query(\"Case > @Case_cutoff\")\n",
    "prevalent_df = prevalent_df.query(\"Case > @Case_cutoff\")\n",
    "\n",
    "print(f\"Finnal Incident Phenotype: {incident_df.shape[0]}\")\n",
    "print(f\"Finnal Prevalent Phenotype: {prevalent_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Assoc\n",
    "\n",
    "1. For prevalence, by Cox \n",
    "2. For incident, by logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 过滤表型\n",
    "\n",
    "保存Case 至少>50的疾病\n",
    "\n",
    "分种族过滤！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppp_prediction.model_v2.models import (\n",
    "    fit_best_model_v2,\n",
    "    fit_ensemble_model_simple_v2,\n",
    "    fit_lightgbm,\n",
    "    fit_xgboost,\n",
    ")\n",
    "\n",
    "\n",
    "def get_predict_v2_from_df(\n",
    "    model,\n",
    "    data,\n",
    "    x_var,\n",
    "):\n",
    "    \"\"\"\n",
    "    merge by idx\n",
    "    \"\"\"\n",
    "\n",
    "    no_na_data = data[x_var].dropna().copy()\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        no_na_data[\"pred\"] = model.predict_proba(no_na_data)[:, 1]\n",
    "    else:\n",
    "        no_na_data[\"pred\"] = model.predict(no_na_data)\n",
    "\n",
    "    return (\n",
    "        data[[]]\n",
    "        .merge(no_na_data[[\"pred\"]], left_index=True, right_index=True, how=\"left\")\n",
    "        .values.flatten()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from ppp_prediction.metrics import cal_binary_metrics\n",
    "\n",
    "\n",
    "# define a function to fit the model, save the result and collect the scores\n",
    "## parallel this function\n",
    "def fit_model_and_save_result(\n",
    "    total_df,  # first col should be eid\n",
    "    label_df,  # first col should be eid\n",
    "    save_dir,\n",
    "    # asssoc_df=None, # used to sort and get top features to downsample, if None then will do assoc\n",
    "    feature_rank_list=None,  # used to downsample the features\n",
    "    min_class_number_cutoff={\"train\": 30, \"validation\": 10, \"test\": 10},\n",
    "    train_test_split_ratio=0.7,\n",
    "    seed=1234,\n",
    "    device=\"cuda\",\n",
    "    topk_list =[5, 10, 20, 50, 100] \n",
    "):\n",
    "    \"\"\"\n",
    "    1. merge the total_df and disease_df\n",
    "    2. check label_df sum is over min_class_number_cutoff; if not return None, and print the error\n",
    "    3. fit the models: 1) full lasso, 2) full xgboost, 3) sample lasso, 4) sample xgboost, 5) sample AutoTabPFN, 6) TabPFN\n",
    "    4. save the results: 1) model, 2) scores of total_df, 3) metrics of models\n",
    "    \"\"\"\n",
    "    # step1: merge and check\n",
    "\n",
    "    ## check the first column\n",
    "    if total_df.columns[0] != \"eid\":\n",
    "        raise ValueError(\"total_df first column should be eid\")\n",
    "    if label_df.columns[0] != \"eid\":\n",
    "        raise ValueError(\"label_df first column should be eid\")\n",
    "\n",
    "    features = total_df.columns[1:].tolist()\n",
    "    label = label_df.columns[1]\n",
    "\n",
    "    ## merge\n",
    "    merged_df = pd.merge(total_df, label_df, on=\"eid\", how=\"inner\")\n",
    "    print(\n",
    "        f\"Found merged samples: {merged_df.shape[0]} while, label_df: {label_df.shape[0]} and total_df: {total_df.shape[0]}\"\n",
    "    )\n",
    "\n",
    "    # step2: fit the model\n",
    "    ## step2.1 Train Test Split\n",
    "    train_df, test_df = train_test_split(\n",
    "        merged_df, test_size=1 - train_test_split_ratio, random_state=seed\n",
    "    )\n",
    "    train_df, val_df = train_test_split(train_df, test_size=0.3, random_state=seed)\n",
    "\n",
    "    score_df = pd.concat(\n",
    "        [\n",
    "            train_df[[\"eid\", label]].copy().assign(Type=\"train\"),\n",
    "            val_df[[\"eid\", label]].copy().assign(Type=\"validation\"),\n",
    "            test_df[[\"eid\", label]].copy().assign(Type=\"test\"),\n",
    "        ]\n",
    "    )\n",
    "    ## step2.2 check the min_class_number\n",
    "    for min_class_number_check_key in [\"train\", \"validation\", \"test\"]:\n",
    "        if min_class_number_check_key == \"train\":\n",
    "            to_check_df = train_df\n",
    "        elif min_class_number_check_key == \"validation\":\n",
    "            to_check_df = val_df\n",
    "        elif min_class_number_check_key == \"test\":\n",
    "            to_check_df = test_df\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"min_class_number_check_key should be in ['train', 'validation', 'test']\"\n",
    "            )\n",
    "        min_class_number = min(to_check_df[label].value_counts())\n",
    "        # the min class number and class name\n",
    "        min_class_name = to_check_df[label].value_counts().idxmin()\n",
    "        if min_class_number < min_class_number_cutoff[min_class_number_check_key]:\n",
    "            print(\n",
    "                f\"Error: {min_class_number_check_key} {min_class_name} has only {min_class_number} samples, less than {min_class_number_cutoff[min_class_number_check_key]}\"\n",
    "            )\n",
    "            return None\n",
    "    print(\n",
    "        f\"Train data have {train_df.shape[0]} samples with {train_df[label].sum():.0f} cases\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Validation data have {val_df.shape[0]} samples with {val_df[label].sum():.0f} cases\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Test data have {test_df.shape[0]} samples with {test_df[label].sum():.0f} cases\"\n",
    "    )\n",
    "\n",
    "    ## check\n",
    "    train_meta_info = {}\n",
    "    ## step2.4 fit the models\n",
    "    modelSaveDir = save_dir / \"models\"\n",
    "    modelSaveDir.mkdir(parents=True, exist_ok=True)\n",
    "    ### 1) Lasso full\n",
    "    lasso_full_savedir = modelSaveDir / \"lasso_full.pkl\"\n",
    "    if lasso_full_savedir.exists():\n",
    "        lasso_full = pickle.load(open(lasso_full_savedir, \"rb\"))\n",
    "        # print(f\"lasso_full loaded\")\n",
    "\n",
    "    else:\n",
    "        lasso_engine = \"cuml\" if device == \"cuda\" else \"sklearn\"\n",
    "        print(merged_df.shape)\n",
    "        if merged_df.shape[0]  < 5000 :\n",
    "            lasso_engine = \"sklearn\"\n",
    "        print(f\"lasso_full start with engine {lasso_engine}\")\n",
    "        (lasso_full, *_) = fit_best_model(\n",
    "            train_df=train_df,\n",
    "            test_df=val_df,\n",
    "            X_var=features,\n",
    "            y_var=label,\n",
    "            method_list=\"Lasso\",\n",
    "            cv=5,\n",
    "            engine=lasso_engine,\n",
    "        )\n",
    "\n",
    "        pickle.dump(lasso_full, open(lasso_full_savedir, \"wb\"))\n",
    "\n",
    "    score_df[\"lasso_full\"] = get_predict_v2_from_df(lasso_full, total_df, features)\n",
    "    # return lasso_full, score_df\n",
    "    train_meta_info[f\"lasso_full\"] = {\n",
    "        \"train_case\": train_df[label].sum(),\n",
    "        \"train_control\": train_df.shape[0] - train_df[label].sum(),\n",
    "    }\n",
    "    del lasso_full\n",
    "\n",
    "    # xgboost full\n",
    "    xgboot_full_savedir = modelSaveDir / \"xgboost_full.pkl\"\n",
    "    if (modelSaveDir / \"xgboost_full.pkl\").exists():\n",
    "        print(f\"xgboost_full loaded\")\n",
    "        xgboost_full_tuned = pickle.load(open(xgboot_full_savedir, \"rb\"))\n",
    "    else:\n",
    "\n",
    "        xgboost_full_tuned, *_ = fit_xgboost(\n",
    "            train=train_df,\n",
    "            xvar=features,\n",
    "            label=label,\n",
    "            tuning=True,\n",
    "            tune_config={\"max_iter\": 100},\n",
    "        )\n",
    "        pickle.dump(xgboost_full_tuned, open(xgboot_full_savedir, \"wb\"))\n",
    "    score_df[\"xgboost_full\"] = get_predict_v2_from_df(\n",
    "        xgboost_full_tuned, total_df, features\n",
    "    )\n",
    "    train_meta_info[f\"xgboost_full\"] = {\n",
    "        \"train_case\": train_df[label].sum(),\n",
    "        \"train_control\": train_df.shape[0] - train_df[label].sum(),\n",
    "    }\n",
    "\n",
    "    del xgboost_full_tuned\n",
    "\n",
    "\n",
    "    for strata in [\"balance\", \"random\"]:  # balance or random\n",
    "        if strata == \"balance\":\n",
    "            disease_train_case = train_df.query(f\"{label} == 1\")\n",
    "            disease_train_control = train_df.query(f\"{label} == 0\").sample(\n",
    "                n=disease_train_case.shape[0], random_state=seed\n",
    "            )\n",
    "            disease_train_sample = pd.concat(\n",
    "                [disease_train_case, disease_train_control]\n",
    "            )\n",
    "        elif strata == \"random\":\n",
    "            if train_df.shape[0] > 10000:\n",
    "                disease_train_sample = train_df.sample(\n",
    "                    n=10000, random_state=seed\n",
    "                )\n",
    "            else:\n",
    "                disease_train_sample = train_df # TODO: Anno this with no sample\n",
    "                \n",
    "        for topk in topk_list:\n",
    "            sig_features = feature_rank_list[:topk]\n",
    "\n",
    "\n",
    "            suffix_name = f\"{topk}_{strata}\"\n",
    "\n",
    "            print(suffix_name)\n",
    "\n",
    "            strata_topk_save_dir = modelSaveDir / f\"{topk}/{strata}\"\n",
    "            strata_topk_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            X_train = disease_train_sample[sig_features]\n",
    "            y_train = disease_train_sample[label]\n",
    "\n",
    "            lasso_sample_topk_savedir = strata_topk_save_dir / f\"lasso_sample.pkl\"\n",
    "            if lasso_sample_topk_savedir.exists():\n",
    "                lasso_sample = pickle.load(open(lasso_sample_topk_savedir, \"rb\"))\n",
    "                print(f\"lasso_sample_{suffix_name} loaded\")\n",
    "            else:\n",
    "                try:\n",
    "                    lasso_engine = \"cuml\" if device == \"cuda\" else \"sklearn\"\n",
    "                    if X_train.shape[0] < 5000:\n",
    "                        lasso_engine = \"sklearn\"\n",
    "                    print(f\"lasso_full start with engine {lasso_engine}\")\n",
    "\n",
    "                    (lasso_sample, *_) = fit_best_model(\n",
    "                        train_df=disease_train_sample,\n",
    "                        test_df=val_df,\n",
    "                        X_var=sig_features,\n",
    "                        y_var=label,\n",
    "                        method_list=\"Lasso\",\n",
    "                        cv=5,\n",
    "                        engine=lasso_engine,\n",
    "                    )\n",
    "                    pickle.dump(\n",
    "                        lasso_sample,\n",
    "                        open(strata_topk_save_dir / f\"lasso_sample.pkl\", \"wb\"),\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"lasso_sample_{topk} failed and erros: {e}\")\n",
    "\n",
    "            score_df[f\"lasso_sample_{suffix_name}\"] = get_predict_v2_from_df(\n",
    "                lasso_sample, total_df, sig_features\n",
    "            )\n",
    "            train_meta_info[f\"lasso_sample_{suffix_name}\"] = {\n",
    "                \"train_case\": disease_train_sample[label].sum(),\n",
    "                \"train_control\": disease_train_sample.shape[0] - disease_train_sample[label].sum(),\n",
    "            }\n",
    "\n",
    "            del lasso_sample\n",
    "\n",
    "            from tabpfn_extensions.post_hoc_ensembles.sklearn_interface import (\n",
    "                AutoTabPFNClassifier,\n",
    "            )\n",
    "\n",
    "            AutoTabPFN_topk_savedir = strata_topk_save_dir / f\"AutoTabPFN.pkl\"\n",
    "            if AutoTabPFN_topk_savedir.exists():\n",
    "                AutoTabPFN = pickle.load(open(AutoTabPFN_topk_savedir, \"rb\"))\n",
    "                print(f\"AutoTabPFN_{topk} loaded\")\n",
    "            else:\n",
    "\n",
    "                try:\n",
    "                    AutoTabPFN = AutoTabPFNClassifier(\n",
    "                        max_time=120, device=\"cuda\" if device == \"cuda\" else \"cpu\"\n",
    "                    )  # 120 seconds tuning time\n",
    "                    AutoTabPFN.fit(X_train, y_train)\n",
    "                    pickle.dump(\n",
    "                        AutoTabPFN, open(strata_topk_save_dir / f\"AutoTabPFN.pkl\", \"wb\")\n",
    "                    )\n",
    "                except:\n",
    "                    print(f\"AutoTabPFN_{topk} failed\")\n",
    "\n",
    "            # score_df[\"AutoTabPFN\"] = AutoTabPFN.predict_proba(X_held_out_test)[:, 1]\n",
    "            score_df[f\"AutoTabPFN_{suffix_name}\"] = AutoTabPFN.predict_proba(\n",
    "                total_df[sig_features]\n",
    "            )[:, 1]\n",
    "            train_meta_info[f\"AutoTabPFN_{suffix_name}\"] = {\n",
    "                \"train_case\": disease_train_sample[label].sum(),\n",
    "                \"train_control\": disease_train_sample.shape[0] - disease_train_sample[label].sum(),\n",
    "            }\n",
    "\n",
    "            del AutoTabPFN\n",
    "            try:\n",
    "                from tabpfn import TabPFNClassifier\n",
    "\n",
    "                TabPFN_topk_savedir = strata_topk_save_dir / f\"TabPFN{topk}.pkl\"\n",
    "                if TabPFN_topk_savedir.exists():\n",
    "                    TabPFN = pickle.load(open(TabPFN_topk_savedir, \"rb\"))\n",
    "                    print(f\"TabPFN_{topk} loaded\")\n",
    "                else:\n",
    "\n",
    "                    TabPFN = TabPFNClassifier(\n",
    "                        device=\"cuda:0\" if device == \"cuda\" else \"cpu\", \n",
    "                        ignore_pretraining_limits=True\n",
    "                    )\n",
    "                    TabPFN.fit(X_train, y_train)\n",
    "                    pickle.dump(\n",
    "                        TabPFN, open(strata_topk_save_dir / f\"TabPFN.pkl\", \"wb\")\n",
    "                    )\n",
    "                # score_df[\"AutoTabPFN\"] = AutoTabPFN.predict_proba(X_held_out_test)[:, 1]\n",
    "                score_df[f\"TabPFN_{suffix_name}\"] = TabPFN.predict_proba(\n",
    "                    total_df[sig_features]\n",
    "                )[:, 1]\n",
    "                train_meta_info[f\"TabPFN_{suffix_name}\"] = {\n",
    "                    \"train_case\": disease_train_sample[label].sum(),\n",
    "                    \"train_control\": disease_train_sample.shape[0] - disease_train_sample[label].sum(),\n",
    "                }\n",
    "                del TabPFN\n",
    "            except:\n",
    "                print(f\"TabPFN {topk} failed\")\n",
    "\n",
    "            # xgboost sampled\n",
    "            xgboost_sample_savedir = strata_topk_save_dir / f\"xgboost_sample.pkl\"\n",
    "            if xgboost_sample_savedir.exists():\n",
    "                xgboost_sample_tuned = pickle.load(open(xgboost_sample_savedir, \"rb\"))\n",
    "                print(f\"xgboost_sample_{topk} loaded\")\n",
    "            else:\n",
    "                try:\n",
    "                    xgboost_sample_tuned, *_ = fit_xgboost(\n",
    "                        train=disease_train_sample,\n",
    "                        xvar=sig_features,\n",
    "                        label=label,\n",
    "                        tuning=True,\n",
    "                        tune_config={\"max_iter\": 100},\n",
    "                    )\n",
    "                    pickle.dump(\n",
    "                        xgboost_sample_tuned,\n",
    "                        open(strata_topk_save_dir / f\"xgboost_sample.pkl\", \"wb\"),\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"xgboost_sample_{topk} failed\")\n",
    "\n",
    "            score_df[f\"xgboost_sample_{suffix_name}\"] = get_predict_v2_from_df(\n",
    "                xgboost_sample_tuned, total_df, sig_features\n",
    "            )\n",
    "            train_meta_info[f\"xgboost_sample_{suffix_name}\"] = {\n",
    "                \"train_case\": disease_train_sample[label].sum(),\n",
    "                \"train_control\": disease_train_sample.shape[0] - disease_train_sample[label].sum(),\n",
    "            }\n",
    "\n",
    "            del xgboost_sample_tuned\n",
    "\n",
    "    score_df.to_feather(save_dir / \"held_out_test.feather\")\n",
    "    pickle.dump(train_meta_info, open(save_dir / \"train_meta_info.pkl\", \"wb\"))\n",
    "    metrics_list = []\n",
    "    for key in score_df.columns[3:]: # eid label Type\n",
    "        to_cal_df = score_df.query(\"Type == 'test'\")[[\"eid\", label, key]].copy().dropna()\n",
    "        res = cal_binary_metrics(\n",
    "            to_cal_df[label], to_cal_df[key], n_resamples=30, ci=True\n",
    "        )\n",
    "        # res = run_cox(to_cal_df, var=key, E=E, T=T, ci=True, n_resamples=100)\n",
    "        res[\"method\"] = key\n",
    "        res.update(train_meta_info[key])\n",
    "        metrics_list.append(res)\n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "    metrics_df.to_csv(save_dir / \"metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultDir = outputDir / \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LEP',\n",
       " 'HAVCR1',\n",
       " 'PALM2',\n",
       " 'IGSF9',\n",
       " 'PRAP1',\n",
       " 'NT5C1A',\n",
       " 'HGF',\n",
       " 'FURIN',\n",
       " 'IL1RN',\n",
       " 'FABP4',\n",
       " 'CPM',\n",
       " 'GDF15',\n",
       " 'ADM',\n",
       " 'YAP1',\n",
       " 'ADAMTSL2',\n",
       " 'PRSS8',\n",
       " 'IFI30',\n",
       " 'RBP5',\n",
       " 'LGALS9',\n",
       " 'CA14',\n",
       " 'FABP3',\n",
       " 'PON3',\n",
       " 'ASGR1',\n",
       " 'SERPINF1',\n",
       " 'HSPB6',\n",
       " 'IL6',\n",
       " 'APOF',\n",
       " 'INHBC',\n",
       " 'FSTL3',\n",
       " 'RBFOX3',\n",
       " 'GPD1',\n",
       " 'PCBD1',\n",
       " 'MXRA8',\n",
       " 'GUSB',\n",
       " 'APCS',\n",
       " 'CTSD',\n",
       " 'GGT1',\n",
       " 'FAM20A',\n",
       " 'F9',\n",
       " 'FGF21',\n",
       " 'CDHR2',\n",
       " 'FTCD',\n",
       " 'ACY1',\n",
       " 'PGF',\n",
       " 'CFI',\n",
       " 'HEG1',\n",
       " 'PLAT',\n",
       " 'NHLRC3',\n",
       " 'CHCHD10',\n",
       " 'CES1',\n",
       " 'IGFBP2',\n",
       " 'RARRES2',\n",
       " 'HJV',\n",
       " 'GLA',\n",
       " 'KRT18',\n",
       " 'IGFBP4',\n",
       " 'TNFRSF10A',\n",
       " 'PTPRB',\n",
       " 'GSTA1',\n",
       " 'ACE2',\n",
       " 'BPIFB2',\n",
       " 'SELE',\n",
       " 'PRCP',\n",
       " 'CDH2',\n",
       " 'MSR1',\n",
       " 'C3',\n",
       " 'OCLN',\n",
       " 'NPL',\n",
       " 'REN',\n",
       " 'VWA1',\n",
       " 'RIDA',\n",
       " 'AFM',\n",
       " 'CKB',\n",
       " 'SETMAR',\n",
       " 'UPB1',\n",
       " 'RTN4R',\n",
       " 'CD80',\n",
       " 'LGALS3BP',\n",
       " 'ADH4',\n",
       " 'LMNB2',\n",
       " 'PLAUR',\n",
       " 'ERBB2',\n",
       " 'SEPTIN8',\n",
       " 'ACTA2',\n",
       " 'PLA2G15',\n",
       " 'TNFRSF10B',\n",
       " 'IL18R1',\n",
       " 'ICAM1',\n",
       " 'FABP1',\n",
       " 'CCL7',\n",
       " 'OXT',\n",
       " 'PAMR1',\n",
       " 'CRIP2',\n",
       " 'SULT2A1',\n",
       " 'RNASE6',\n",
       " 'NPC2',\n",
       " 'C1RL',\n",
       " 'ADGRG1',\n",
       " 'WFIKKN2',\n",
       " 'SCLY',\n",
       " 'RELT',\n",
       " 'IGFBPL1',\n",
       " 'CCN3',\n",
       " 'LILRB4',\n",
       " 'DTNB',\n",
       " 'SHBG',\n",
       " 'CDCP1',\n",
       " 'TNFRSF1A',\n",
       " 'ADH1B',\n",
       " 'FUOM',\n",
       " 'BST2',\n",
       " 'VSIG4',\n",
       " 'GSTA3',\n",
       " 'CTHRC1',\n",
       " 'TIMP1',\n",
       " 'CCL3',\n",
       " 'CSF1',\n",
       " 'NOS3',\n",
       " 'IGSF3',\n",
       " 'RNASE4',\n",
       " 'SORBS1',\n",
       " 'CFB',\n",
       " 'KYNU',\n",
       " 'SSC5D',\n",
       " 'IGF2R',\n",
       " 'SIGLEC1',\n",
       " 'HNMT',\n",
       " 'SCARB2',\n",
       " 'STAB2',\n",
       " 'PDZK1',\n",
       " 'IMMT',\n",
       " 'TCTN3',\n",
       " 'LDLR',\n",
       " 'COL6A3',\n",
       " 'LAIR1',\n",
       " 'FCAMR',\n",
       " 'LILRA5',\n",
       " 'PTP4A3',\n",
       " 'ADAM12',\n",
       " 'CST3',\n",
       " 'ADGRG2',\n",
       " 'TNFRSF6B',\n",
       " 'GOLM2',\n",
       " 'IL10RB',\n",
       " 'PTS',\n",
       " 'MAD1L1',\n",
       " 'SLITRK1',\n",
       " 'SERPIND1',\n",
       " 'RNASE1',\n",
       " 'SORD',\n",
       " 'MMP7',\n",
       " 'CRELD1',\n",
       " 'GHR',\n",
       " 'C19orf12',\n",
       " 'RRM2',\n",
       " 'NOMO1',\n",
       " 'CCL16',\n",
       " 'THOP1',\n",
       " 'LAMP2',\n",
       " 'ELN',\n",
       " 'TNFRSF12A',\n",
       " 'LPL',\n",
       " 'SSC4D',\n",
       " 'PIGR',\n",
       " 'CD163',\n",
       " 'NCAN',\n",
       " 'SFRP1',\n",
       " 'BAIAP2',\n",
       " 'SNCG',\n",
       " 'CRLF1',\n",
       " 'MRC1',\n",
       " 'POLR2F',\n",
       " 'LECT2',\n",
       " 'TPP1',\n",
       " 'ST6GAL1',\n",
       " 'BMPER',\n",
       " 'APBB1IP',\n",
       " 'SEMA3F',\n",
       " 'GFRA1',\n",
       " 'IGFBP1',\n",
       " 'CTSO',\n",
       " 'IGFBP7',\n",
       " 'FGF23',\n",
       " 'KHK',\n",
       " 'RNASET2',\n",
       " 'CA5A',\n",
       " 'COL18A1',\n",
       " 'FGFR2',\n",
       " 'EPHA1',\n",
       " 'CNTN3',\n",
       " 'BCAN',\n",
       " 'PLIN1',\n",
       " 'MYBPC1',\n",
       " 'CFP',\n",
       " 'ITGA5',\n",
       " 'CD300E',\n",
       " 'HAVCR2',\n",
       " 'MME',\n",
       " 'ADAMTS15',\n",
       " 'ENPP6',\n",
       " 'IL16',\n",
       " 'EFHD1',\n",
       " 'AMBP',\n",
       " 'CLMP',\n",
       " 'EFNA4',\n",
       " 'SLAMF8',\n",
       " 'TNF',\n",
       " 'STC1',\n",
       " 'SLC39A5',\n",
       " 'CD302',\n",
       " 'MVK',\n",
       " 'ANGPTL2',\n",
       " 'F7',\n",
       " 'MYL3',\n",
       " 'SIGLEC7',\n",
       " 'PCSK9',\n",
       " 'LRTM2',\n",
       " 'CDA',\n",
       " 'EZR',\n",
       " 'APLP1',\n",
       " 'CD59',\n",
       " 'CNTN5',\n",
       " 'TREM2',\n",
       " 'C2',\n",
       " 'WARS',\n",
       " 'GGH',\n",
       " 'AGER',\n",
       " 'ART3',\n",
       " 'ITGBL1',\n",
       " 'MZB1',\n",
       " 'STC2',\n",
       " 'IL18',\n",
       " 'MFAP5',\n",
       " 'NADK',\n",
       " 'CXCL10',\n",
       " 'CD72',\n",
       " 'PON2',\n",
       " 'IFNLR1',\n",
       " 'CALB2',\n",
       " 'ANGPTL4',\n",
       " 'ITGA11',\n",
       " 'CRHBP',\n",
       " 'VWC2L',\n",
       " 'PBLD',\n",
       " 'PLXNB2',\n",
       " 'ORM1',\n",
       " 'CD74',\n",
       " 'FCN1',\n",
       " 'GCHFR',\n",
       " 'CILP',\n",
       " 'CD99L2',\n",
       " 'LCAT',\n",
       " 'OSM',\n",
       " 'ALDH1A1',\n",
       " 'LGALS4',\n",
       " 'NT5E',\n",
       " 'TGFA',\n",
       " 'CTSZ',\n",
       " 'PSAP',\n",
       " 'APOD',\n",
       " 'DPT',\n",
       " 'HSPG2',\n",
       " 'ADGRD1',\n",
       " 'ENPP7',\n",
       " 'C1S',\n",
       " 'SIGLEC8',\n",
       " 'MEGF9',\n",
       " 'HIP1R',\n",
       " 'SHISA5',\n",
       " 'TNFRSF11A',\n",
       " 'DDT',\n",
       " 'IL13RA1',\n",
       " 'CTSB',\n",
       " 'GBP1',\n",
       " 'IL17RB',\n",
       " 'EGLN1',\n",
       " 'AGRN',\n",
       " 'ARSA',\n",
       " 'TGFBR2',\n",
       " 'VNN1',\n",
       " 'DSG2',\n",
       " 'THBS4',\n",
       " 'CREG1',\n",
       " 'MFGE8',\n",
       " 'TNFRSF1B',\n",
       " 'CSTB',\n",
       " 'CXCL13',\n",
       " 'LGALS1',\n",
       " 'CHCHD6',\n",
       " 'TPR',\n",
       " 'CD300C',\n",
       " 'SNRPB2',\n",
       " 'PLA2G1B',\n",
       " 'NCAM2',\n",
       " 'EFNA1',\n",
       " 'KIAA0319',\n",
       " 'TNFRSF11B',\n",
       " 'GIPC2',\n",
       " 'AKR7L',\n",
       " 'MOG',\n",
       " 'TCOF1',\n",
       " 'CLSTN3',\n",
       " 'SMOC1',\n",
       " 'LRRC25',\n",
       " 'SEZ6L',\n",
       " 'PHOSPHO1',\n",
       " 'DPY30',\n",
       " 'SIGLEC10',\n",
       " 'FBP1',\n",
       " 'CPXM2',\n",
       " 'ACAA1',\n",
       " 'DCXR',\n",
       " 'PRRT3',\n",
       " 'CCL4',\n",
       " 'VEGFA',\n",
       " 'SERPINE1',\n",
       " 'GRPEL1',\n",
       " 'GPR37',\n",
       " 'EDN1',\n",
       " 'CD4',\n",
       " 'CANT1',\n",
       " 'PTH',\n",
       " 'LAMP3',\n",
       " 'MPO',\n",
       " 'SMAD5',\n",
       " 'CLEC4D',\n",
       " 'SLC9A3R2',\n",
       " 'AMIGO2',\n",
       " 'CLEC6A',\n",
       " 'B2M',\n",
       " 'CD28',\n",
       " 'CLEC4G',\n",
       " 'IDUA',\n",
       " 'ECHDC3',\n",
       " 'FETUB',\n",
       " 'ANG',\n",
       " 'MTUS1',\n",
       " 'TIMD4',\n",
       " 'DDAH1',\n",
       " 'CDHR5',\n",
       " 'KIT',\n",
       " 'ERMAP',\n",
       " 'SUOX',\n",
       " 'IL18BP',\n",
       " 'CEACAM8',\n",
       " 'B3GNT7',\n",
       " 'IFNGR2',\n",
       " 'LSP1',\n",
       " 'COLEC12',\n",
       " 'ELOA',\n",
       " 'ADIPOQ',\n",
       " 'CFD',\n",
       " 'RNF149',\n",
       " 'SPON2',\n",
       " 'FSTL1',\n",
       " 'KITLG',\n",
       " 'AGXT',\n",
       " 'BCHE',\n",
       " 'GSR',\n",
       " 'CHI3L1',\n",
       " 'AMY2A',\n",
       " 'F10',\n",
       " 'CCL18',\n",
       " 'FLT4',\n",
       " 'SCPEP1',\n",
       " 'CD83',\n",
       " 'A1BG',\n",
       " 'HSD11B1',\n",
       " 'MMP9',\n",
       " 'KDR',\n",
       " 'OBP2B',\n",
       " 'NAGPA',\n",
       " 'HHEX',\n",
       " 'CTBS',\n",
       " 'TGFB1',\n",
       " 'ITGAV',\n",
       " 'GALNT10',\n",
       " 'CCL21',\n",
       " 'LRRN1',\n",
       " 'MENT',\n",
       " 'HEPH',\n",
       " 'QSOX1',\n",
       " 'BAP18',\n",
       " 'CCL22',\n",
       " 'PTN',\n",
       " 'ACP5',\n",
       " 'HAO1',\n",
       " 'LRCH4',\n",
       " 'LBR',\n",
       " 'DPP6',\n",
       " 'CD274',\n",
       " 'CD300A',\n",
       " 'PTPRC',\n",
       " 'MET',\n",
       " 'EPS8L2',\n",
       " 'CES2',\n",
       " 'NFASC',\n",
       " 'FAS',\n",
       " 'LGMN',\n",
       " 'ZBTB17',\n",
       " 'CCL20',\n",
       " 'VSNL1',\n",
       " 'TALDO1',\n",
       " 'LILRB1',\n",
       " 'SEL1L',\n",
       " 'AMY2B',\n",
       " 'AGR3',\n",
       " 'CCN5',\n",
       " 'SWAP70',\n",
       " 'SGSH',\n",
       " 'GRN',\n",
       " 'PTPRR',\n",
       " 'INHBB',\n",
       " 'ENO3',\n",
       " 'CD200',\n",
       " 'MAMDC4',\n",
       " 'EDA2R',\n",
       " 'GFER',\n",
       " 'PILRA',\n",
       " 'CDH15',\n",
       " 'FGA',\n",
       " 'CTSL',\n",
       " 'MB',\n",
       " 'FGFBP1',\n",
       " 'IL2RA',\n",
       " 'HNRNPUL1',\n",
       " 'MMP12',\n",
       " 'PLG',\n",
       " 'PROS1',\n",
       " 'VMO1',\n",
       " 'CD34',\n",
       " 'HPSE',\n",
       " 'SCG3',\n",
       " 'CEMIP2',\n",
       " 'LRP11',\n",
       " 'LEPR',\n",
       " 'BSG',\n",
       " 'KCTD5',\n",
       " 'GLB1',\n",
       " 'ACVRL1',\n",
       " 'PVR',\n",
       " 'VWC2',\n",
       " 'THY1',\n",
       " 'LTBP3',\n",
       " 'FABP5',\n",
       " 'CEACAM1',\n",
       " 'AHNAK',\n",
       " 'PALM',\n",
       " 'FN1',\n",
       " 'CST7',\n",
       " 'CXCL16',\n",
       " 'ARSB',\n",
       " 'TFPI',\n",
       " 'TMPRSS5',\n",
       " 'GSN',\n",
       " 'SRP14',\n",
       " 'CCN1',\n",
       " 'C1QTNF1',\n",
       " 'GASK1A',\n",
       " 'NXPH3',\n",
       " 'ADAMTS8',\n",
       " 'ADGRE1',\n",
       " 'MARCO',\n",
       " 'FCN2',\n",
       " 'MICB_MICA',\n",
       " 'GPRC5C',\n",
       " 'RBP7',\n",
       " 'S100P',\n",
       " 'ADAM8',\n",
       " 'FST',\n",
       " 'GPHA2',\n",
       " 'NOS1',\n",
       " 'PHLDB1',\n",
       " 'THBS2',\n",
       " 'VGF',\n",
       " 'WFDC2',\n",
       " 'OGN',\n",
       " 'SCRG1',\n",
       " 'ST3GAL1',\n",
       " 'LBP',\n",
       " 'AREG',\n",
       " 'TNFSF14',\n",
       " 'ADA2',\n",
       " 'EGFL7',\n",
       " 'TREH',\n",
       " 'BCAT1',\n",
       " 'GAST',\n",
       " 'CD101',\n",
       " 'DMP1',\n",
       " 'CD22',\n",
       " 'ASGR2',\n",
       " 'DIPK2B',\n",
       " 'AIFM1',\n",
       " 'CCN4',\n",
       " 'IL1RAP',\n",
       " 'DEFB4A_DEFB4B',\n",
       " 'OMG',\n",
       " 'CCDC80',\n",
       " 'P4HB',\n",
       " 'TNFRSF14',\n",
       " 'WFDC1',\n",
       " 'SERPINB8',\n",
       " 'IL19',\n",
       " 'SCGB1A1',\n",
       " 'INSL5',\n",
       " 'ODAM',\n",
       " 'PTGR1',\n",
       " 'COL4A1',\n",
       " 'FUS',\n",
       " 'GM2A',\n",
       " 'ROBO1',\n",
       " 'AMOT',\n",
       " 'SLIT2',\n",
       " 'PPL',\n",
       " 'DNER',\n",
       " 'SERPINA5',\n",
       " 'IL1RL1',\n",
       " 'APEX1',\n",
       " 'PSIP1',\n",
       " 'CA6',\n",
       " 'MTDH',\n",
       " 'TOP2B',\n",
       " 'ESM1',\n",
       " 'CBS',\n",
       " 'UMOD',\n",
       " 'SAA4',\n",
       " 'DNM3',\n",
       " 'GFRA3',\n",
       " 'SIAE',\n",
       " 'GHRL',\n",
       " 'VSTM2L',\n",
       " 'RET',\n",
       " 'CXCL11',\n",
       " 'CHGB',\n",
       " 'HMOX2',\n",
       " 'ADGRF5',\n",
       " 'MEP1A',\n",
       " 'PLA2G10',\n",
       " 'CCL5',\n",
       " 'LRPAP1',\n",
       " 'MATN2',\n",
       " 'XRCC4',\n",
       " 'KLF4',\n",
       " 'ENAH',\n",
       " 'ERN1',\n",
       " 'NUCB2',\n",
       " 'MYH9',\n",
       " 'NPTXR',\n",
       " 'TFRC',\n",
       " 'S100A12',\n",
       " 'SMNDC1',\n",
       " 'RASSF2',\n",
       " 'MMP8',\n",
       " 'ERP44',\n",
       " 'MDK',\n",
       " 'CCL19',\n",
       " 'NFATC3',\n",
       " 'FASLG',\n",
       " 'SEZ6',\n",
       " 'PXN',\n",
       " 'VEGFB',\n",
       " 'IGSF8',\n",
       " 'CSF1R',\n",
       " 'NID1',\n",
       " 'EIF4EBP1',\n",
       " 'SFRP4',\n",
       " 'BCL2',\n",
       " 'KLRD1',\n",
       " 'CPE',\n",
       " 'QDPR',\n",
       " 'TNFSF13B',\n",
       " 'PGLYRP1',\n",
       " 'SELP',\n",
       " 'CDHR1',\n",
       " 'DTYMK',\n",
       " 'LEO1',\n",
       " 'B4GAT1',\n",
       " 'OPTC',\n",
       " 'SERPINA7',\n",
       " 'EPO',\n",
       " 'LILRA2',\n",
       " 'CD5',\n",
       " 'PSME1',\n",
       " 'ACY3',\n",
       " 'TACSTD2',\n",
       " 'STX4',\n",
       " 'OGFR',\n",
       " 'PKD2',\n",
       " 'PAM',\n",
       " 'IL15',\n",
       " 'BNIP3L',\n",
       " 'CR1',\n",
       " 'SORT1',\n",
       " 'RBKS',\n",
       " 'ZHX2',\n",
       " 'LUZP2',\n",
       " 'FMNL1',\n",
       " 'RPL14',\n",
       " 'NECTIN2',\n",
       " 'CES3',\n",
       " 'GIGYF2',\n",
       " 'C1R',\n",
       " 'DHPS',\n",
       " 'SCARF1',\n",
       " 'SPINK6',\n",
       " 'B4GALT1',\n",
       " 'SLITRK2',\n",
       " 'BID',\n",
       " 'PLTP',\n",
       " 'TIMP3',\n",
       " 'SIGLEC6',\n",
       " 'GPKOW',\n",
       " 'PDGFC',\n",
       " 'SMPD1',\n",
       " 'S100A11',\n",
       " 'ATRN',\n",
       " 'CAPG',\n",
       " 'IL12A_IL12B',\n",
       " 'TOMM20',\n",
       " 'FOLR2',\n",
       " 'PILRB',\n",
       " 'LTA4H',\n",
       " 'TNFRSF9',\n",
       " 'GAL',\n",
       " 'SIT1',\n",
       " 'CXCL6',\n",
       " 'ISM1',\n",
       " 'CKAP4',\n",
       " 'AHSG',\n",
       " 'NDUFS6',\n",
       " 'PTPRN2',\n",
       " 'PODXL2',\n",
       " 'DNAJB1',\n",
       " 'CLUL1',\n",
       " 'TMSB10',\n",
       " 'SCGB3A2',\n",
       " 'ERBB3',\n",
       " 'CD40',\n",
       " 'TXNRD1',\n",
       " 'CDKN1A',\n",
       " 'MUC13',\n",
       " 'NFKBIE',\n",
       " 'CD2AP',\n",
       " 'CRH',\n",
       " 'CHL1',\n",
       " 'DPP7',\n",
       " 'MAPK9',\n",
       " 'SHMT1']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_rank_list = pd.read_csv(\n",
    "    \"../ppp/cvmdPrediction/V2/output/01-assoc/Prot/Hypertension.tsv\",\n",
    "    sep=\"\\t\",\n",
    ")\n",
    "fake_rank_list.sort_values(\"pvalue\", inplace=True)\n",
    "fake_rank_list = fake_rank_list.query(\"pvalue <1e-5\")\n",
    "fake_rank_list = fake_rank_list[[\"var\", \"coef\"]]\n",
    "fake_rank_list[\"abs_coef\"] = fake_rank_list[\"coef\"].abs()\n",
    "fake_rank_list.sort_values(\"abs_coef\", ascending=False, inplace=True)\n",
    "fake_rank_list = fake_rank_list[\"var\"].tolist()\n",
    "fake_rank_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently, Running incident hypertension and Asian\n",
      "Found merged samples: 986 while, label_df: 53021 and total_df: 986\n",
      "Train data have 483 samples with 136 cases\n",
      "Validation data have 207 samples with 54 cases\n",
      "Test data have 296 samples with 81 cases\n",
      "xgboost_full loaded\n",
      "5_balance\n",
      "lasso_sample_5_balance loaded\n",
      "AutoTabPFN_5 loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost_sample_5 loaded\n",
      "10_balance\n",
      "lasso_sample_10_balance loaded\n",
      "AutoTabPFN_10 loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost_sample_10 loaded\n",
      "20_balance\n",
      "lasso_sample_20_balance loaded\n",
      "AutoTabPFN_20 loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost_sample_20 loaded\n",
      "5_random\n",
      "lasso_sample_5_random loaded\n",
      "AutoTabPFN_5 loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost_sample_5 loaded\n",
      "10_random\n",
      "lasso_sample_10_random loaded\n",
      "AutoTabPFN_10 loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost_sample_10 loaded\n",
      "20_random\n",
      "lasso_sample_20_random loaded\n",
      "AutoTabPFN_20 loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "/deeplearning/xutingfeng/miniforge3/envs/ml/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost_sample_20 loaded\n"
     ]
    }
   ],
   "source": [
    "# for disease in diseaseList:\n",
    "for disease in [Path(\"V1/data/Lancet_Digital_Health_2019/hypertension.feather\")]:\n",
    "    diseaseName = disease.stem\n",
    "    # for c_groupbyVar in used_groupByVar:\n",
    "    for c_groupbyVar in [\"Asian\"]:\n",
    "        # for label in [\"prevalent\", \"incident\"]:\n",
    "        c_groupbyVar_eids = covariates_df.query(f\"{groupByVar} == @c_groupbyVar\").eid\n",
    "        for label in [\"incident\", \"prevalent\"]:\n",
    "            print(f\"Currently, Running {label} {diseaseName} and {c_groupbyVar}\")\n",
    "            label_df = pd.read_feather(disease).query(\"eid in @omicsData.eid\")\n",
    "            fit_model_and_save_result(\n",
    "                total_df=omicsData.query(f\"eid in @c_groupbyVar_eids\"),\n",
    "                label_df=label_df[[\"eid\", label]],\n",
    "                save_dir=resultDir / f\"{diseaseName}/{c_groupbyVar}/{label}\",\n",
    "                feature_rank_list=fake_rank_list,  # currently use the fake rank list, better use assoc on whole set or run assoc on the train set\n",
    "                device=\"cuda\",\n",
    "                topk_list = [5,10,20]\n",
    "            )\n",
    "            break\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lasso_full': {'train_case': 136, 'train_control': 347},\n",
       " 'xgboost_full': {'train_case': 136, 'train_control': 347},\n",
       " 'lasso_sample_5_balance': {'train_case': 136, 'train_control': 136},\n",
       " 'AutoTabPFN_5_balance': {'train_case': 136, 'train_control': 136},\n",
       " 'TabPFN_5_balance': {'train_case': 136, 'train_control': 136},\n",
       " 'xgboost_sample_5_balance': {'train_case': 136, 'train_control': 136},\n",
       " 'lasso_sample_10_balance': {'train_case': 136, 'train_control': 136},\n",
       " 'AutoTabPFN_10_balance': {'train_case': 136, 'train_control': 136},\n",
       " 'TabPFN_10_balance': {'train_case': 136, 'train_control': 136},\n",
       " 'xgboost_sample_10_balance': {'train_case': 136, 'train_control': 136},\n",
       " 'lasso_sample_20_balance': {'train_case': 136, 'train_control': 136},\n",
       " 'AutoTabPFN_20_balance': {'train_case': 136, 'train_control': 136},\n",
       " 'TabPFN_20_balance': {'train_case': 136, 'train_control': 136},\n",
       " 'xgboost_sample_20_balance': {'train_case': 136, 'train_control': 136},\n",
       " 'lasso_sample_5_random': {'train_case': 136, 'train_control': 347},\n",
       " 'AutoTabPFN_5_random': {'train_case': 136, 'train_control': 347},\n",
       " 'TabPFN_5_random': {'train_case': 136, 'train_control': 347},\n",
       " 'xgboost_sample_5_random': {'train_case': 136, 'train_control': 347},\n",
       " 'lasso_sample_10_random': {'train_case': 136, 'train_control': 347},\n",
       " 'AutoTabPFN_10_random': {'train_case': 136, 'train_control': 347},\n",
       " 'TabPFN_10_random': {'train_case': 136, 'train_control': 347},\n",
       " 'xgboost_sample_10_random': {'train_case': 136, 'train_control': 347},\n",
       " 'lasso_sample_20_random': {'train_case': 136, 'train_control': 347},\n",
       " 'AutoTabPFN_20_random': {'train_case': 136, 'train_control': 347},\n",
       " 'TabPFN_20_random': {'train_case': 136, 'train_control': 347},\n",
       " 'xgboost_sample_20_random': {'train_case': 136, 'train_control': 347}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle(\"V1/output/test/hypertension/Asian/incident/train_meta_info.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score_df = pd.read_feather(\"V1/output/test/hypertension/Asian/incident/held_out_test.feather\")\n",
    "metrics_list = []\n",
    "for key in score_df.columns[3:]:\n",
    "    to_cal_df = score_df.query(\"Type == 'test'\")[[\"eid\", label, key]].copy().dropna()\n",
    "    res = cal_binary_metrics(\n",
    "        to_cal_df[label], to_cal_df[key], n_resamples=30, ci=True\n",
    "    )\n",
    "    # res = run_cox(to_cal_df, var=key, E=E, T=T, ci=True, n_resamples=100)\n",
    "    res[\"method\"] = key\n",
    "    metrics_list.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eid</th>\n",
       "      <th>incident</th>\n",
       "      <th>Type</th>\n",
       "      <th>lasso_full</th>\n",
       "      <th>xgboost_full</th>\n",
       "      <th>lasso_sample_5_balance</th>\n",
       "      <th>AutoTabPFN_5_balance</th>\n",
       "      <th>TabPFN_5_balance</th>\n",
       "      <th>xgboost_sample_5_balance</th>\n",
       "      <th>lasso_sample_10_balance</th>\n",
       "      <th>...</th>\n",
       "      <th>TabPFN_5_random</th>\n",
       "      <th>xgboost_sample_5_random</th>\n",
       "      <th>lasso_sample_10_random</th>\n",
       "      <th>AutoTabPFN_10_random</th>\n",
       "      <th>TabPFN_10_random</th>\n",
       "      <th>xgboost_sample_10_random</th>\n",
       "      <th>lasso_sample_20_random</th>\n",
       "      <th>AutoTabPFN_20_random</th>\n",
       "      <th>TabPFN_20_random</th>\n",
       "      <th>xgboost_sample_20_random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>4965815</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>-0.092701</td>\n",
       "      <td>0.292974</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.526283</td>\n",
       "      <td>0.516403</td>\n",
       "      <td>0.502275</td>\n",
       "      <td>0.414261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296645</td>\n",
       "      <td>0.293855</td>\n",
       "      <td>0.293136</td>\n",
       "      <td>0.278459</td>\n",
       "      <td>0.281512</td>\n",
       "      <td>0.301346</td>\n",
       "      <td>0.248743</td>\n",
       "      <td>0.223627</td>\n",
       "      <td>0.248202</td>\n",
       "      <td>0.281330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>5027923</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.377075</td>\n",
       "      <td>0.292899</td>\n",
       "      <td>0.328333</td>\n",
       "      <td>0.391850</td>\n",
       "      <td>0.378329</td>\n",
       "      <td>0.501991</td>\n",
       "      <td>0.293440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150532</td>\n",
       "      <td>0.283658</td>\n",
       "      <td>0.215500</td>\n",
       "      <td>0.163865</td>\n",
       "      <td>0.162240</td>\n",
       "      <td>0.293866</td>\n",
       "      <td>0.214128</td>\n",
       "      <td>0.162959</td>\n",
       "      <td>0.167436</td>\n",
       "      <td>0.252588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1493006</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.227678</td>\n",
       "      <td>0.293577</td>\n",
       "      <td>0.608341</td>\n",
       "      <td>0.527133</td>\n",
       "      <td>0.568381</td>\n",
       "      <td>0.502429</td>\n",
       "      <td>0.562029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331318</td>\n",
       "      <td>0.293165</td>\n",
       "      <td>0.325195</td>\n",
       "      <td>0.320722</td>\n",
       "      <td>0.319020</td>\n",
       "      <td>0.298950</td>\n",
       "      <td>0.380376</td>\n",
       "      <td>0.363825</td>\n",
       "      <td>0.370440</td>\n",
       "      <td>0.329644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>2069763</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.140574</td>\n",
       "      <td>0.292864</td>\n",
       "      <td>0.507239</td>\n",
       "      <td>0.508844</td>\n",
       "      <td>0.496955</td>\n",
       "      <td>0.502460</td>\n",
       "      <td>0.424892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260455</td>\n",
       "      <td>0.318641</td>\n",
       "      <td>0.277791</td>\n",
       "      <td>0.255335</td>\n",
       "      <td>0.271815</td>\n",
       "      <td>0.304927</td>\n",
       "      <td>0.245602</td>\n",
       "      <td>0.254672</td>\n",
       "      <td>0.238606</td>\n",
       "      <td>0.306260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1238126</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.526148</td>\n",
       "      <td>0.293153</td>\n",
       "      <td>0.437103</td>\n",
       "      <td>0.539578</td>\n",
       "      <td>0.497289</td>\n",
       "      <td>0.502277</td>\n",
       "      <td>0.433640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267647</td>\n",
       "      <td>0.279121</td>\n",
       "      <td>0.266707</td>\n",
       "      <td>0.260187</td>\n",
       "      <td>0.269442</td>\n",
       "      <td>0.300437</td>\n",
       "      <td>0.309659</td>\n",
       "      <td>0.270176</td>\n",
       "      <td>0.283464</td>\n",
       "      <td>0.269230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>4554890</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>0.397083</td>\n",
       "      <td>0.293353</td>\n",
       "      <td>0.590334</td>\n",
       "      <td>0.521645</td>\n",
       "      <td>0.557839</td>\n",
       "      <td>0.502628</td>\n",
       "      <td>0.552649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331240</td>\n",
       "      <td>0.281947</td>\n",
       "      <td>0.313858</td>\n",
       "      <td>0.313708</td>\n",
       "      <td>0.317855</td>\n",
       "      <td>0.311196</td>\n",
       "      <td>0.300511</td>\n",
       "      <td>0.299060</td>\n",
       "      <td>0.306942</td>\n",
       "      <td>0.318519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1446008</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>0.007065</td>\n",
       "      <td>0.292452</td>\n",
       "      <td>0.265654</td>\n",
       "      <td>0.437533</td>\n",
       "      <td>0.355252</td>\n",
       "      <td>0.501954</td>\n",
       "      <td>0.297122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137325</td>\n",
       "      <td>0.278776</td>\n",
       "      <td>0.200939</td>\n",
       "      <td>0.151250</td>\n",
       "      <td>0.167215</td>\n",
       "      <td>0.295600</td>\n",
       "      <td>0.184728</td>\n",
       "      <td>0.139354</td>\n",
       "      <td>0.149213</td>\n",
       "      <td>0.275370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>5749777</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.051586</td>\n",
       "      <td>0.292444</td>\n",
       "      <td>0.555780</td>\n",
       "      <td>0.525538</td>\n",
       "      <td>0.538814</td>\n",
       "      <td>0.502391</td>\n",
       "      <td>0.570118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306804</td>\n",
       "      <td>0.279121</td>\n",
       "      <td>0.298739</td>\n",
       "      <td>0.296500</td>\n",
       "      <td>0.296195</td>\n",
       "      <td>0.302735</td>\n",
       "      <td>0.310842</td>\n",
       "      <td>0.263840</td>\n",
       "      <td>0.281228</td>\n",
       "      <td>0.294891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>2142357</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>0.642048</td>\n",
       "      <td>0.293347</td>\n",
       "      <td>0.453031</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>0.498237</td>\n",
       "      <td>0.502462</td>\n",
       "      <td>0.423815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278600</td>\n",
       "      <td>0.294503</td>\n",
       "      <td>0.281022</td>\n",
       "      <td>0.271331</td>\n",
       "      <td>0.277141</td>\n",
       "      <td>0.300253</td>\n",
       "      <td>0.300726</td>\n",
       "      <td>0.280095</td>\n",
       "      <td>0.302931</td>\n",
       "      <td>0.289849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>3951224</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>0.076920</td>\n",
       "      <td>0.292329</td>\n",
       "      <td>0.498208</td>\n",
       "      <td>0.477814</td>\n",
       "      <td>0.475133</td>\n",
       "      <td>0.502305</td>\n",
       "      <td>0.386447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235909</td>\n",
       "      <td>0.272796</td>\n",
       "      <td>0.265620</td>\n",
       "      <td>0.237151</td>\n",
       "      <td>0.239276</td>\n",
       "      <td>0.300829</td>\n",
       "      <td>0.242799</td>\n",
       "      <td>0.219048</td>\n",
       "      <td>0.198424</td>\n",
       "      <td>0.257772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>986 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         eid  incident   Type  lasso_full  xgboost_full  \\\n",
       "755  4965815         0  train   -0.092701      0.292974   \n",
       "766  5027923         1  train    0.377075      0.292899   \n",
       "101  1493006         0  train    0.227678      0.293577   \n",
       "208  2069763         0  train    0.140574      0.292864   \n",
       "57   1238126         0  train    0.526148      0.293153   \n",
       "..       ...       ...    ...         ...           ...   \n",
       "688  4554890         1   test    0.397083      0.293353   \n",
       "96   1446008         0   test    0.007065      0.292452   \n",
       "927  5749777         0   test   -0.051586      0.292444   \n",
       "218  2142357         0   test    0.642048      0.293347   \n",
       "567  3951224         0   test    0.076920      0.292329   \n",
       "\n",
       "     lasso_sample_5_balance  AutoTabPFN_5_balance  TabPFN_5_balance  \\\n",
       "755                0.489898              0.526283          0.516403   \n",
       "766                0.328333              0.391850          0.378329   \n",
       "101                0.608341              0.527133          0.568381   \n",
       "208                0.507239              0.508844          0.496955   \n",
       "57                 0.437103              0.539578          0.497289   \n",
       "..                      ...                   ...               ...   \n",
       "688                0.590334              0.521645          0.557839   \n",
       "96                 0.265654              0.437533          0.355252   \n",
       "927                0.555780              0.525538          0.538814   \n",
       "218                0.453031              0.515100          0.498237   \n",
       "567                0.498208              0.477814          0.475133   \n",
       "\n",
       "     xgboost_sample_5_balance  lasso_sample_10_balance  ...  TabPFN_5_random  \\\n",
       "755                  0.502275                 0.414261  ...         0.296645   \n",
       "766                  0.501991                 0.293440  ...         0.150532   \n",
       "101                  0.502429                 0.562029  ...         0.331318   \n",
       "208                  0.502460                 0.424892  ...         0.260455   \n",
       "57                   0.502277                 0.433640  ...         0.267647   \n",
       "..                        ...                      ...  ...              ...   \n",
       "688                  0.502628                 0.552649  ...         0.331240   \n",
       "96                   0.501954                 0.297122  ...         0.137325   \n",
       "927                  0.502391                 0.570118  ...         0.306804   \n",
       "218                  0.502462                 0.423815  ...         0.278600   \n",
       "567                  0.502305                 0.386447  ...         0.235909   \n",
       "\n",
       "     xgboost_sample_5_random  lasso_sample_10_random  AutoTabPFN_10_random  \\\n",
       "755                 0.293855                0.293136              0.278459   \n",
       "766                 0.283658                0.215500              0.163865   \n",
       "101                 0.293165                0.325195              0.320722   \n",
       "208                 0.318641                0.277791              0.255335   \n",
       "57                  0.279121                0.266707              0.260187   \n",
       "..                       ...                     ...                   ...   \n",
       "688                 0.281947                0.313858              0.313708   \n",
       "96                  0.278776                0.200939              0.151250   \n",
       "927                 0.279121                0.298739              0.296500   \n",
       "218                 0.294503                0.281022              0.271331   \n",
       "567                 0.272796                0.265620              0.237151   \n",
       "\n",
       "     TabPFN_10_random  xgboost_sample_10_random  lasso_sample_20_random  \\\n",
       "755          0.281512                  0.301346                0.248743   \n",
       "766          0.162240                  0.293866                0.214128   \n",
       "101          0.319020                  0.298950                0.380376   \n",
       "208          0.271815                  0.304927                0.245602   \n",
       "57           0.269442                  0.300437                0.309659   \n",
       "..                ...                       ...                     ...   \n",
       "688          0.317855                  0.311196                0.300511   \n",
       "96           0.167215                  0.295600                0.184728   \n",
       "927          0.296195                  0.302735                0.310842   \n",
       "218          0.277141                  0.300253                0.300726   \n",
       "567          0.239276                  0.300829                0.242799   \n",
       "\n",
       "     AutoTabPFN_20_random  TabPFN_20_random  xgboost_sample_20_random  \n",
       "755              0.223627          0.248202                  0.281330  \n",
       "766              0.162959          0.167436                  0.252588  \n",
       "101              0.363825          0.370440                  0.329644  \n",
       "208              0.254672          0.238606                  0.306260  \n",
       "57               0.270176          0.283464                  0.269230  \n",
       "..                    ...               ...                       ...  \n",
       "688              0.299060          0.306942                  0.318519  \n",
       "96               0.139354          0.149213                  0.275370  \n",
       "927              0.263840          0.281228                  0.294891  \n",
       "218              0.280095          0.302931                  0.289849  \n",
       "567              0.219048          0.198424                  0.257772  \n",
       "\n",
       "[986 rows x 29 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>AUC_UCI</th>\n",
       "      <th>AUC_LCI</th>\n",
       "      <th>ACC</th>\n",
       "      <th>ACC_UCI</th>\n",
       "      <th>ACC_LCI</th>\n",
       "      <th>Macro_F1</th>\n",
       "      <th>Macro_F1_UCI</th>\n",
       "      <th>Macro_F1_LCI</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>...</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Specificity_UCI</th>\n",
       "      <th>Specificity_LCI</th>\n",
       "      <th>APR</th>\n",
       "      <th>APR_UCI</th>\n",
       "      <th>APR_LCI</th>\n",
       "      <th>N</th>\n",
       "      <th>N_case</th>\n",
       "      <th>N_control</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.502268</td>\n",
       "      <td>0.555907</td>\n",
       "      <td>0.436467</td>\n",
       "      <td>0.439189</td>\n",
       "      <td>0.469341</td>\n",
       "      <td>0.407517</td>\n",
       "      <td>0.438548</td>\n",
       "      <td>0.476080</td>\n",
       "      <td>0.373261</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.365430</td>\n",
       "      <td>0.267458</td>\n",
       "      <td>0.283973</td>\n",
       "      <td>0.324844</td>\n",
       "      <td>0.167140</td>\n",
       "      <td>296</td>\n",
       "      <td>81</td>\n",
       "      <td>215</td>\n",
       "      <td>lasso_full</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.507063</td>\n",
       "      <td>0.555447</td>\n",
       "      <td>0.441243</td>\n",
       "      <td>0.462838</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.402618</td>\n",
       "      <td>0.457632</td>\n",
       "      <td>0.498329</td>\n",
       "      <td>0.391520</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386047</td>\n",
       "      <td>0.441160</td>\n",
       "      <td>0.335434</td>\n",
       "      <td>0.273266</td>\n",
       "      <td>0.345590</td>\n",
       "      <td>0.231252</td>\n",
       "      <td>296</td>\n",
       "      <td>81</td>\n",
       "      <td>215</td>\n",
       "      <td>xgboost_full</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.547287</td>\n",
       "      <td>0.592940</td>\n",
       "      <td>0.495733</td>\n",
       "      <td>0.408784</td>\n",
       "      <td>0.461318</td>\n",
       "      <td>0.349155</td>\n",
       "      <td>0.405793</td>\n",
       "      <td>0.461264</td>\n",
       "      <td>0.356864</td>\n",
       "      <td>0.876543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.271467</td>\n",
       "      <td>0.188014</td>\n",
       "      <td>0.290790</td>\n",
       "      <td>0.339548</td>\n",
       "      <td>0.218660</td>\n",
       "      <td>296</td>\n",
       "      <td>81</td>\n",
       "      <td>215</td>\n",
       "      <td>lasso_sample_5_balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.553431</td>\n",
       "      <td>0.626756</td>\n",
       "      <td>0.471127</td>\n",
       "      <td>0.712838</td>\n",
       "      <td>0.766301</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.541336</td>\n",
       "      <td>0.629057</td>\n",
       "      <td>0.502667</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.911628</td>\n",
       "      <td>0.948561</td>\n",
       "      <td>0.883860</td>\n",
       "      <td>0.312638</td>\n",
       "      <td>0.356771</td>\n",
       "      <td>0.248548</td>\n",
       "      <td>296</td>\n",
       "      <td>81</td>\n",
       "      <td>215</td>\n",
       "      <td>AutoTabPFN_5_balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.559575</td>\n",
       "      <td>0.635579</td>\n",
       "      <td>0.494821</td>\n",
       "      <td>0.672297</td>\n",
       "      <td>0.707010</td>\n",
       "      <td>0.612669</td>\n",
       "      <td>0.552821</td>\n",
       "      <td>0.602721</td>\n",
       "      <td>0.504395</td>\n",
       "      <td>0.283951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.818605</td>\n",
       "      <td>0.876812</td>\n",
       "      <td>0.789968</td>\n",
       "      <td>0.300019</td>\n",
       "      <td>0.378804</td>\n",
       "      <td>0.239189</td>\n",
       "      <td>296</td>\n",
       "      <td>81</td>\n",
       "      <td>215</td>\n",
       "      <td>TabPFN_5_balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.503417</td>\n",
       "      <td>0.557347</td>\n",
       "      <td>0.415408</td>\n",
       "      <td>0.442568</td>\n",
       "      <td>0.485051</td>\n",
       "      <td>0.398311</td>\n",
       "      <td>0.441490</td>\n",
       "      <td>0.498245</td>\n",
       "      <td>0.374552</td>\n",
       "      <td>0.728395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334884</td>\n",
       "      <td>0.390921</td>\n",
       "      <td>0.265208</td>\n",
       "      <td>0.308282</td>\n",
       "      <td>0.395410</td>\n",
       "      <td>0.232654</td>\n",
       "      <td>296</td>\n",
       "      <td>81</td>\n",
       "      <td>215</td>\n",
       "      <td>xgboost_sample_5_balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.539994</td>\n",
       "      <td>0.592860</td>\n",
       "      <td>0.450866</td>\n",
       "      <td>0.510135</td>\n",
       "      <td>0.548226</td>\n",
       "      <td>0.465287</td>\n",
       "      <td>0.496333</td>\n",
       "      <td>0.541157</td>\n",
       "      <td>0.440416</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.540851</td>\n",
       "      <td>0.397833</td>\n",
       "      <td>0.288991</td>\n",
       "      <td>0.347849</td>\n",
       "      <td>0.251865</td>\n",
       "      <td>296</td>\n",
       "      <td>81</td>\n",
       "      <td>215</td>\n",
       "      <td>lasso_sample_10_balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.560609</td>\n",
       "      <td>0.629105</td>\n",
       "      <td>0.505568</td>\n",
       "      <td>0.385135</td>\n",
       "      <td>0.409713</td>\n",
       "      <td>0.336909</td>\n",
       "      <td>0.375904</td>\n",
       "      <td>0.424995</td>\n",
       "      <td>0.332471</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181395</td>\n",
       "      <td>0.209535</td>\n",
       "      <td>0.143181</td>\n",
       "      <td>0.297760</td>\n",
       "      <td>0.355634</td>\n",
       "      <td>0.243873</td>\n",
       "      <td>296</td>\n",
       "      <td>81</td>\n",
       "      <td>215</td>\n",
       "      <td>AutoTabPFN_10_balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.555268</td>\n",
       "      <td>0.622460</td>\n",
       "      <td>0.485252</td>\n",
       "      <td>0.587838</td>\n",
       "      <td>0.635473</td>\n",
       "      <td>0.539274</td>\n",
       "      <td>0.539388</td>\n",
       "      <td>0.597022</td>\n",
       "      <td>0.460949</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.687325</td>\n",
       "      <td>0.583244</td>\n",
       "      <td>0.290135</td>\n",
       "      <td>0.320555</td>\n",
       "      <td>0.222659</td>\n",
       "      <td>296</td>\n",
       "      <td>81</td>\n",
       "      <td>215</td>\n",
       "      <td>TabPFN_10_balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.535228</td>\n",
       "      <td>0.608521</td>\n",
       "      <td>0.481197</td>\n",
       "      <td>0.516892</td>\n",
       "      <td>0.562416</td>\n",
       "      <td>0.456926</td>\n",
       "      <td>0.504397</td>\n",
       "      <td>0.566195</td>\n",
       "      <td>0.459484</td>\n",
       "      <td>0.654321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.523781</td>\n",
       "      <td>0.426546</td>\n",
       "      <td>0.290264</td>\n",
       "      <td>0.343983</td>\n",
       "      <td>0.210833</td>\n",
       "      <td>296</td>\n",
       "      <td>81</td>\n",
       "      <td>215</td>\n",
       "      <td>xgboost_sample_10_balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.546770</td>\n",
       "      <td>0.605154</td>\n",
       "      <td>0.481659</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.552872</td>\n",
       "      <td>0.484291</td>\n",
       "      <td>0.495455</td>\n",
       "      <td>0.530688</td>\n",
       "      <td>0.436450</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483721</td>\n",
       "      <td>0.544907</td>\n",
       "      <td>0.418108</td>\n",
       "      <td>0.315983</td>\n",
       "      <td>0.411451</td>\n",
       "      <td>0.247321</td>\n",
       "      <td>296</td>\n",
       "      <td>81</td>\n",
       "      <td>215</td>\n",
       "      <td>lasso_sample_20_balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.544818</td>\n",
       "      <td>0.605228</td>\n",
       "      <td>0.467179</td>\n",
       "      <td>0.628378</td>\n",
       "      <td>0.671706</td>\n",
       "      <td>0.580152</td>\n",
       "      <td>0.549280</td>\n",
       "      <td>0.614312</td>\n",
       "      <td>0.507754</td>\n",
       "      <td>0.382716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.720930</td>\n",
       "      <td>0.753723</td>\n",
       "      <td>0.673401</td>\n",
       "      <td>0.307466</td>\n",
       "      <td>0.371098</td>\n",
       "      <td>0.242233</td>\n",
       "      <td>296</td>\n",
       "      <td>81</td>\n",
       "      <td>215</td>\n",
       "      <td>AutoTabPFN_20_balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.545162</td>\n",
       "      <td>0.635721</td>\n",
       "      <td>0.483083</td>\n",
       "      <td>0.381757</td>\n",
       "      <td>0.426689</td>\n",
       "      <td>0.340541</td>\n",
       "      <td>0.372990</td>\n",
       "      <td>0.423865</td>\n",
       "      <td>0.312522</td>\n",
       "      <td>0.913580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181395</td>\n",
       "      <td>0.216098</td>\n",
       "      <td>0.135831</td>\n",
       "      <td>0.299490</td>\n",
       "      <td>0.352980</td>\n",
       "      <td>0.194922</td>\n",
       "      <td>296</td>\n",
       "      <td>81</td>\n",
       "      <td>215</td>\n",
       "      <td>TabPFN_20_balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.527505</td>\n",
       "      <td>0.579089</td>\n",
       "      <td>0.443853</td>\n",
       "      <td>0.665541</td>\n",
       "      <td>0.701520</td>\n",
       "      <td>0.619764</td>\n",
       "      <td>0.563714</td>\n",
       "      <td>0.605139</td>\n",
       "      <td>0.515749</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.828596</td>\n",
       "      <td>0.747858</td>\n",
       "      <td>0.316870</td>\n",
       "      <td>0.370672</td>\n",
       "      <td>0.211311</td>\n",
       "      <td>296</td>\n",
       "      <td>81</td>\n",
       "      <td>215</td>\n",
       "      <td>xgboost_sample_20_balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.569308</td>\n",
       "      <td>0.647120</td>\n",
       "      <td>0.486945</td>\n",
       "      <td>0.614865</td>\n",
       "      <td>0.668919</td>\n",
       "      <td>0.560811</td>\n",
       "      <td>0.553154</td>\n",
       "      <td>0.611433</td>\n",
       "      <td>0.504975</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.679070</td>\n",
       "      <td>0.737476</td>\n",
       "      <td>0.622635</td>\n",
       "      <td>0.307764</td>\n",
       "      <td>0.356020</td>\n",
       "      <td>0.246259</td>\n",
       "      <td>296</td>\n",
       "      <td>81</td>\n",
       "      <td>215</td>\n",
       "      <td>lasso_sample_5_random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.554350</td>\n",
       "      <td>0.623071</td>\n",
       "      <td>0.499155</td>\n",
       "      <td>0.591216</td>\n",
       "      <td>0.631757</td>\n",
       "      <td>0.541385</td>\n",
       "      <td>0.542036</td>\n",
       "      <td>0.594001</td>\n",
       "      <td>0.502249</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.632558</td>\n",
       "      <td>0.701106</td>\n",
       "      <td>0.576468</td>\n",
       "      <td>0.307436</td>\n",
       "      <td>0.360277</td>\n",
       "      <td>0.207445</td>\n",
       "      <td>296</td>\n",
       "      <td>81</td>\n",
       "      <td>215</td>\n",
       "      <td>AutoTabPFN_5_random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.562331</td>\n",
       "      <td>0.615944</td>\n",
       "      <td>0.492279</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.683361</td>\n",
       "      <td>0.589949</td>\n",
       "      <td>0.555562</td>\n",
       "      <td>0.601314</td>\n",
       "      <td>0.494820</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702326</td>\n",
       "      <td>0.744805</td>\n",
       "      <td>0.622715</td>\n",
       "      <td>0.302977</td>\n",
       "      <td>0.367374</td>\n",
       "      <td>0.208016</td>\n",
       "      <td>296</td>\n",
       "      <td>81</td>\n",
       "      <td>215</td>\n",
       "      <td>TabPFN_5_random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.446110</td>\n",
       "      <td>0.508641</td>\n",
       "      <td>0.386649</td>\n",
       "      <td>0.287162</td>\n",
       "      <td>0.333277</td>\n",
       "      <td>0.246284</td>\n",
       "      <td>0.246201</td>\n",
       "      <td>0.283535</td>\n",
       "      <td>0.207548</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037209</td>\n",
       "      <td>0.056421</td>\n",
       "      <td>0.016936</td>\n",
       "      <td>0.234338</td>\n",
       "      <td>0.283512</td>\n",
       "      <td>0.157896</td>\n",
       "      <td>296</td>\n",
       "      <td>81</td>\n",
       "      <td>215</td>\n",
       "      <td>xgboost_sample_5_random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.569308</td>\n",
       "      <td>0.643119</td>\n",
       "      <td>0.505046</td>\n",
       "      <td>0.614865</td>\n",
       "      <td>0.683699</td>\n",
       "      <td>0.562922</td>\n",
       "      <td>0.553154</td>\n",
       "      <td>0.593212</td>\n",
       "      <td>0.514798</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.679070</td>\n",
       "      <td>0.718575</td>\n",
       "      <td>0.604726</td>\n",
       "      <td>0.307764</td>\n",
       "      <td>0.373300</td>\n",
       "      <td>0.203105</td>\n",
       "      <td>296</td>\n",
       "      <td>81</td>\n",
       "      <td>215</td>\n",
       "      <td>lasso_sample_10_random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.564111</td>\n",
       "      <td>0.639819</td>\n",
       "      <td>0.501067</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.697804</td>\n",
       "      <td>0.583530</td>\n",
       "      <td>0.558334</td>\n",
       "      <td>0.597734</td>\n",
       "      <td>0.502081</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.753028</td>\n",
       "      <td>0.662033</td>\n",
       "      <td>0.301900</td>\n",
       "      <td>0.383903</td>\n",
       "      <td>0.222425</td>\n",
       "      <td>296</td>\n",
       "      <td>81</td>\n",
       "      <td>215</td>\n",
       "      <td>AutoTabPFN_10_random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.556589</td>\n",
       "      <td>0.631095</td>\n",
       "      <td>0.477785</td>\n",
       "      <td>0.655405</td>\n",
       "      <td>0.726351</td>\n",
       "      <td>0.607179</td>\n",
       "      <td>0.556104</td>\n",
       "      <td>0.620162</td>\n",
       "      <td>0.516644</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.776744</td>\n",
       "      <td>0.850611</td>\n",
       "      <td>0.744072</td>\n",
       "      <td>0.298796</td>\n",
       "      <td>0.349735</td>\n",
       "      <td>0.222367</td>\n",
       "      <td>296</td>\n",
       "      <td>81</td>\n",
       "      <td>215</td>\n",
       "      <td>TabPFN_10_random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.526672</td>\n",
       "      <td>0.602751</td>\n",
       "      <td>0.453916</td>\n",
       "      <td>0.371622</td>\n",
       "      <td>0.424155</td>\n",
       "      <td>0.323649</td>\n",
       "      <td>0.363220</td>\n",
       "      <td>0.410692</td>\n",
       "      <td>0.304761</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176744</td>\n",
       "      <td>0.202988</td>\n",
       "      <td>0.149477</td>\n",
       "      <td>0.327466</td>\n",
       "      <td>0.403571</td>\n",
       "      <td>0.227950</td>\n",
       "      <td>296</td>\n",
       "      <td>81</td>\n",
       "      <td>215</td>\n",
       "      <td>xgboost_sample_10_random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.538616</td>\n",
       "      <td>0.591557</td>\n",
       "      <td>0.466732</td>\n",
       "      <td>0.408784</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.364527</td>\n",
       "      <td>0.407262</td>\n",
       "      <td>0.449472</td>\n",
       "      <td>0.356699</td>\n",
       "      <td>0.839506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246512</td>\n",
       "      <td>0.288628</td>\n",
       "      <td>0.202996</td>\n",
       "      <td>0.287943</td>\n",
       "      <td>0.329590</td>\n",
       "      <td>0.220643</td>\n",
       "      <td>296</td>\n",
       "      <td>81</td>\n",
       "      <td>215</td>\n",
       "      <td>lasso_sample_20_random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.544703</td>\n",
       "      <td>0.620107</td>\n",
       "      <td>0.476386</td>\n",
       "      <td>0.570946</td>\n",
       "      <td>0.615541</td>\n",
       "      <td>0.523311</td>\n",
       "      <td>0.530376</td>\n",
       "      <td>0.607004</td>\n",
       "      <td>0.466386</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.595349</td>\n",
       "      <td>0.648082</td>\n",
       "      <td>0.542245</td>\n",
       "      <td>0.314454</td>\n",
       "      <td>0.422030</td>\n",
       "      <td>0.228328</td>\n",
       "      <td>296</td>\n",
       "      <td>81</td>\n",
       "      <td>215</td>\n",
       "      <td>AutoTabPFN_20_random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.547459</td>\n",
       "      <td>0.589204</td>\n",
       "      <td>0.471156</td>\n",
       "      <td>0.510135</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.479392</td>\n",
       "      <td>0.496333</td>\n",
       "      <td>0.549039</td>\n",
       "      <td>0.433341</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.531703</td>\n",
       "      <td>0.421581</td>\n",
       "      <td>0.299551</td>\n",
       "      <td>0.358046</td>\n",
       "      <td>0.176944</td>\n",
       "      <td>296</td>\n",
       "      <td>81</td>\n",
       "      <td>215</td>\n",
       "      <td>TabPFN_20_random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.552196</td>\n",
       "      <td>0.618920</td>\n",
       "      <td>0.465834</td>\n",
       "      <td>0.530405</td>\n",
       "      <td>0.586318</td>\n",
       "      <td>0.465878</td>\n",
       "      <td>0.512321</td>\n",
       "      <td>0.557376</td>\n",
       "      <td>0.461189</td>\n",
       "      <td>0.617284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497674</td>\n",
       "      <td>0.541799</td>\n",
       "      <td>0.434714</td>\n",
       "      <td>0.310491</td>\n",
       "      <td>0.386944</td>\n",
       "      <td>0.211540</td>\n",
       "      <td>296</td>\n",
       "      <td>81</td>\n",
       "      <td>215</td>\n",
       "      <td>xgboost_sample_20_random</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AUC   AUC_UCI   AUC_LCI       ACC   ACC_UCI   ACC_LCI  Macro_F1  \\\n",
       "0   0.502268  0.555907  0.436467  0.439189  0.469341  0.407517  0.438548   \n",
       "1   0.507063  0.555447  0.441243  0.462838  0.500000  0.402618  0.457632   \n",
       "2   0.547287  0.592940  0.495733  0.408784  0.461318  0.349155  0.405793   \n",
       "3   0.553431  0.626756  0.471127  0.712838  0.766301  0.675676  0.541336   \n",
       "4   0.559575  0.635579  0.494821  0.672297  0.707010  0.612669  0.552821   \n",
       "5   0.503417  0.557347  0.415408  0.442568  0.485051  0.398311  0.441490   \n",
       "6   0.539994  0.592860  0.450866  0.510135  0.548226  0.465287  0.496333   \n",
       "7   0.560609  0.629105  0.505568  0.385135  0.409713  0.336909  0.375904   \n",
       "8   0.555268  0.622460  0.485252  0.587838  0.635473  0.539274  0.539388   \n",
       "9   0.535228  0.608521  0.481197  0.516892  0.562416  0.456926  0.504397   \n",
       "10  0.546770  0.605154  0.481659  0.513514  0.552872  0.484291  0.495455   \n",
       "11  0.544818  0.605228  0.467179  0.628378  0.671706  0.580152  0.549280   \n",
       "12  0.545162  0.635721  0.483083  0.381757  0.426689  0.340541  0.372990   \n",
       "13  0.527505  0.579089  0.443853  0.665541  0.701520  0.619764  0.563714   \n",
       "14  0.569308  0.647120  0.486945  0.614865  0.668919  0.560811  0.553154   \n",
       "15  0.554350  0.623071  0.499155  0.591216  0.631757  0.541385  0.542036   \n",
       "16  0.562331  0.615944  0.492279  0.625000  0.683361  0.589949  0.555562   \n",
       "17  0.446110  0.508641  0.386649  0.287162  0.333277  0.246284  0.246201   \n",
       "18  0.569308  0.643119  0.505046  0.614865  0.683699  0.562922  0.553154   \n",
       "19  0.564111  0.639819  0.501067  0.625000  0.697804  0.583530  0.558334   \n",
       "20  0.556589  0.631095  0.477785  0.655405  0.726351  0.607179  0.556104   \n",
       "21  0.526672  0.602751  0.453916  0.371622  0.424155  0.323649  0.363220   \n",
       "22  0.538616  0.591557  0.466732  0.408784  0.459459  0.364527  0.407262   \n",
       "23  0.544703  0.620107  0.476386  0.570946  0.615541  0.523311  0.530376   \n",
       "24  0.547459  0.589204  0.471156  0.510135  0.540541  0.479392  0.496333   \n",
       "25  0.552196  0.618920  0.465834  0.530405  0.586318  0.465878  0.512321   \n",
       "\n",
       "    Macro_F1_UCI  Macro_F1_LCI  Sensitivity  ...  Specificity  \\\n",
       "0       0.476080      0.373261     0.740741  ...     0.325581   \n",
       "1       0.498329      0.391520     0.666667  ...     0.386047   \n",
       "2       0.461264      0.356864     0.876543  ...     0.232558   \n",
       "3       0.629057      0.502667     0.185185  ...     0.911628   \n",
       "4       0.602721      0.504395     0.283951  ...     0.818605   \n",
       "5       0.498245      0.374552     0.728395  ...     0.334884   \n",
       "6       0.541157      0.440416     0.629630  ...     0.465116   \n",
       "7       0.424995      0.332471     0.925926  ...     0.181395   \n",
       "8       0.597022      0.460949     0.481481  ...     0.627907   \n",
       "9       0.566195      0.459484     0.654321  ...     0.465116   \n",
       "10      0.530688      0.436450     0.592593  ...     0.483721   \n",
       "11      0.614312      0.507754     0.382716  ...     0.720930   \n",
       "12      0.423865      0.312522     0.913580  ...     0.181395   \n",
       "13      0.605139      0.515749     0.333333  ...     0.790698   \n",
       "14      0.611433      0.504975     0.444444  ...     0.679070   \n",
       "15      0.594001      0.502249     0.481481  ...     0.632558   \n",
       "16      0.601314      0.494820     0.419753  ...     0.702326   \n",
       "17      0.283535      0.207548     0.950617  ...     0.037209   \n",
       "18      0.593212      0.514798     0.444444  ...     0.679070   \n",
       "19      0.597734      0.502081     0.432099  ...     0.697674   \n",
       "20      0.620162      0.516644     0.333333  ...     0.776744   \n",
       "21      0.410692      0.304761     0.888889  ...     0.176744   \n",
       "22      0.449472      0.356699     0.839506  ...     0.246512   \n",
       "23      0.607004      0.466386     0.506173  ...     0.595349   \n",
       "24      0.549039      0.433341     0.629630  ...     0.465116   \n",
       "25      0.557376      0.461189     0.617284  ...     0.497674   \n",
       "\n",
       "    Specificity_UCI  Specificity_LCI       APR   APR_UCI   APR_LCI    N  \\\n",
       "0          0.365430         0.267458  0.283973  0.324844  0.167140  296   \n",
       "1          0.441160         0.335434  0.273266  0.345590  0.231252  296   \n",
       "2          0.271467         0.188014  0.290790  0.339548  0.218660  296   \n",
       "3          0.948561         0.883860  0.312638  0.356771  0.248548  296   \n",
       "4          0.876812         0.789968  0.300019  0.378804  0.239189  296   \n",
       "5          0.390921         0.265208  0.308282  0.395410  0.232654  296   \n",
       "6          0.540851         0.397833  0.288991  0.347849  0.251865  296   \n",
       "7          0.209535         0.143181  0.297760  0.355634  0.243873  296   \n",
       "8          0.687325         0.583244  0.290135  0.320555  0.222659  296   \n",
       "9          0.523781         0.426546  0.290264  0.343983  0.210833  296   \n",
       "10         0.544907         0.418108  0.315983  0.411451  0.247321  296   \n",
       "11         0.753723         0.673401  0.307466  0.371098  0.242233  296   \n",
       "12         0.216098         0.135831  0.299490  0.352980  0.194922  296   \n",
       "13         0.828596         0.747858  0.316870  0.370672  0.211311  296   \n",
       "14         0.737476         0.622635  0.307764  0.356020  0.246259  296   \n",
       "15         0.701106         0.576468  0.307436  0.360277  0.207445  296   \n",
       "16         0.744805         0.622715  0.302977  0.367374  0.208016  296   \n",
       "17         0.056421         0.016936  0.234338  0.283512  0.157896  296   \n",
       "18         0.718575         0.604726  0.307764  0.373300  0.203105  296   \n",
       "19         0.753028         0.662033  0.301900  0.383903  0.222425  296   \n",
       "20         0.850611         0.744072  0.298796  0.349735  0.222367  296   \n",
       "21         0.202988         0.149477  0.327466  0.403571  0.227950  296   \n",
       "22         0.288628         0.202996  0.287943  0.329590  0.220643  296   \n",
       "23         0.648082         0.542245  0.314454  0.422030  0.228328  296   \n",
       "24         0.531703         0.421581  0.299551  0.358046  0.176944  296   \n",
       "25         0.541799         0.434714  0.310491  0.386944  0.211540  296   \n",
       "\n",
       "    N_case  N_control                     method  \n",
       "0       81        215                 lasso_full  \n",
       "1       81        215               xgboost_full  \n",
       "2       81        215     lasso_sample_5_balance  \n",
       "3       81        215       AutoTabPFN_5_balance  \n",
       "4       81        215           TabPFN_5_balance  \n",
       "5       81        215   xgboost_sample_5_balance  \n",
       "6       81        215    lasso_sample_10_balance  \n",
       "7       81        215      AutoTabPFN_10_balance  \n",
       "8       81        215          TabPFN_10_balance  \n",
       "9       81        215  xgboost_sample_10_balance  \n",
       "10      81        215    lasso_sample_20_balance  \n",
       "11      81        215      AutoTabPFN_20_balance  \n",
       "12      81        215          TabPFN_20_balance  \n",
       "13      81        215  xgboost_sample_20_balance  \n",
       "14      81        215      lasso_sample_5_random  \n",
       "15      81        215        AutoTabPFN_5_random  \n",
       "16      81        215            TabPFN_5_random  \n",
       "17      81        215    xgboost_sample_5_random  \n",
       "18      81        215     lasso_sample_10_random  \n",
       "19      81        215       AutoTabPFN_10_random  \n",
       "20      81        215           TabPFN_10_random  \n",
       "21      81        215   xgboost_sample_10_random  \n",
       "22      81        215     lasso_sample_20_random  \n",
       "23      81        215       AutoTabPFN_20_random  \n",
       "24      81        215           TabPFN_20_random  \n",
       "25      81        215   xgboost_sample_20_random  \n",
       "\n",
       "[26 rows x 22 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(metrics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1BG</td>\n",
       "      <td>0.002819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAMDC</td>\n",
       "      <td>0.004625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AARSD1</td>\n",
       "      <td>0.002607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABCA2</td>\n",
       "      <td>-0.000706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABHD14B</td>\n",
       "      <td>0.001628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2906</th>\n",
       "      <td>ZNRD2</td>\n",
       "      <td>-0.004057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td>ZNRF4</td>\n",
       "      <td>-0.003088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>ZP3</td>\n",
       "      <td>-0.00232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>ZP4</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>ZPR1</td>\n",
       "      <td>0.000845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2911 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1\n",
       "0        A1BG  0.002819\n",
       "1       AAMDC  0.004625\n",
       "2      AARSD1  0.002607\n",
       "3       ABCA2 -0.000706\n",
       "4     ABHD14B  0.001628\n",
       "...       ...       ...\n",
       "2906    ZNRD2 -0.004057\n",
       "2907    ZNRF4 -0.003088\n",
       "2908      ZP3  -0.00232\n",
       "2909      ZP4  0.000005\n",
       "2910     ZPR1  0.000845\n",
       "\n",
       "[2911 rows x 2 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([model.feature_names_in_, model[-1].coef_]).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
